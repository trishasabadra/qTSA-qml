{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b7b1e-602b-4715-83f7-a504ddaf425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrate pytorch with Bayesian Optimization to potentially improve results - not working yet :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea3cddb1-1a1c-4c4c-883b-03eb23640d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer, AdamOptimizer\n",
    "from pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n",
    "import matplotlib.pyplot as plt\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a04c42c-0d54-456c-9dfd-ea7552ce5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f321702f-d7f2-485b-a896-709fb9ca25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angle encoding - maps data to rotation angles for quantum gates.\n",
    "def get_angles(x):\n",
    "    beta0 = 2 * np.arcsin(np.sqrt(x[1] ** 2) / np.sqrt(x[0] ** 2 + x[1] ** 2 + 1e-12))\n",
    "    beta1 = 2 * np.arcsin(np.sqrt(x[3] ** 2) / np.sqrt(x[2] ** 2 + x[3] ** 2 + 1e-12))\n",
    "    beta2 = 2 * np.arcsin(np.linalg.norm(x[2:]) / np.linalg.norm(x))\n",
    "\n",
    "    return np.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2])\n",
    "    # return np.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2], dtype=np.float32)\n",
    "    # return torch.tensor([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0324581f-1d3d-479a-9ff3-6461e43cf957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD MATLAB DATA\n",
    "# import scipy.io\n",
    "# mat = scipy.io.loadmat('/Users/trisha/Documents/CSIRE/SMIB/SMIB_feature.mat')\n",
    "# X = mat[\"X_train\"]\n",
    "# Y = mat[\"Y_train\"]\n",
    "\n",
    "# X = np.array(X)\n",
    "# Y = np.array(Y)\n",
    "\n",
    "# # write to a file\n",
    "# np.savetxt(\"X_train.txt\", X)\n",
    "# np.savetxt(\"Y_train.txt\", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "da9e705d-f3bd-47bf-b369-22759a9984d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD .TXT DATA\n",
    "data = np.loadtxt(\"trainX.txt\")\n",
    "X = data[:, 0:2]\n",
    "Y = np.loadtxt(\"trainY.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4766aee0-135a-4ea7-a4c9-2fa7a4d4d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process data - convert to tensor\n",
    "Y = torch.tensor(np.where(Y == 0, -1.0, 1.0), dtype=torch.float32)\n",
    "# print(Y)\n",
    "\n",
    "padding = np.ones((len(X), 2)) * 0.1\n",
    "X_pad = np.c_[X, padding]\n",
    "normalization = np.sqrt(np.sum(X_pad**2, -1))\n",
    "X_norm = (X_pad.T / normalization).T\n",
    "features = np.array([get_angles(x) for x in X_norm], requires_grad=False)\n",
    "features = torch.tensor(features, dtype=torch.float32)\n",
    "# print(features)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "np.random.seed(0)\n",
    "num_data = len(Y)\n",
    "num_train = int(0.75 * num_data) # 75% of the data for training\n",
    "index = np.random.permutation(num_data) # permutation of integers 0 -> len(Y) (indices)\n",
    "# print(index)\n",
    "\n",
    "feats_train = features[index[:num_train]]\n",
    "feats_val = features[index[num_train:]]\n",
    "\n",
    "Y_train = Y[index[:num_train]]\n",
    "Y_val = Y[index[num_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "55424423-d169-4b0c-b433-9e7899a93e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIRCUIT + COST FUNCTIONS\n",
    "def state_preparation(a):\n",
    "    qml.RY(a[0], wires=0)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[1], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[2], wires=1)\n",
    "\n",
    "    qml.PauliX(wires=0)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[3], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[4], wires=1)\n",
    "    qml.PauliX(wires=0)\n",
    "\n",
    "def layer(layer_weights):\n",
    "    for wire in range(num_qubits):\n",
    "        qml.Rot(*layer_weights[wire], wires=wire)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    for i in range(num_qubits): \n",
    "        qml.CZ(wires=[i, (i+1) % num_qubits]) \n",
    "    for i in range(num_qubits): \n",
    "        qml.S(wires=i)  \n",
    "\n",
    "@qml.qnode(dev, interface='torch') # added interface = torch\n",
    "def circuit(weights, x):\n",
    "    state_preparation(x)\n",
    "    for wire in range(num_qubits):\n",
    "        qml.Hadamard(wires=wire)\n",
    "    for layer_weights in weights:\n",
    "        layer(layer_weights)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    # return np.mean((labels - qml.math.stack(predictions)) ** 2)\n",
    "    # return torch.mean((labels - predictions) ** 2)\n",
    "\n",
    "    # print(\"labels: \", labels)\n",
    "    # print(\"predictions: \", predictions)\n",
    "\n",
    "    labels = labels.float()  # Convert to float if necessary\n",
    "    predictions = predictions.float()  # Convert to float if necessary\n",
    "    \n",
    "    # Compute mean squared error\n",
    "    mse = torch.mean((labels - predictions) ** 2)\n",
    "    return mse\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    return acc / len(labels)\n",
    "\n",
    "def cost(weights, bias, X, Y):\n",
    "    predictions = variational_classifier(weights, bias, X.T)\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d402eb8c-470e-47b7-95ed-cc503a21fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Bayesian optimization\n",
    "def objective(params):\n",
    "    global num_qubits\n",
    "    # num_qubits = 2\n",
    "    num_qubits, num_layers, learning_rate, opt_steps = params\n",
    "    opt_steps = int(opt_steps)\n",
    "    num_qubits = int(num_qubits)\n",
    "    num_layers = int(num_layers)\n",
    "\n",
    "    print(\"num_qubits: \", num_qubits, \" num layers: \", num_layers, \" learning rate: \", learning_rate, \" opt_steps: \", opt_steps)\n",
    "\n",
    "    # Initialize variables\n",
    "    # weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "    # bias_init = np.array(0.0, requires_grad=True) \n",
    "    # opt = AdamOptimizer(learning_rate)\n",
    "    \n",
    "    # torch variables\n",
    "    # weights_init = 0.01 * torch.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "    # bias_init = torch.tensor(0.0, requires_grad=True)\n",
    "    weights_init = torch.nn.Parameter(0.01 * torch.randn(num_layers, num_qubits, 3))\n",
    "    bias_init = torch.nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    optimizer = optim.Adam([weights_init, bias_init], lr=learning_rate)\n",
    "    \n",
    "    batch_size = 128\n",
    "\n",
    "    # Train the variational classifier\n",
    "    weights = weights_init\n",
    "    bias = bias_init\n",
    "    acc_val = 0\n",
    "    for it in range(opt_steps):\n",
    "        batch_index = np.random.randint(0, num_train, (batch_size,)) # array of random integers \n",
    "        feats_train_batch = feats_train[batch_index]\n",
    "        Y_train_batch = Y_train[batch_index]\n",
    "        \n",
    "        # weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, clusters_train_batch)\n",
    "\n",
    "        # tensor opt step\n",
    "        optimizer.zero_grad()\n",
    "        loss = cost(weights, bias, feats_train_batch, Y_train_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute predictions on train and validation set\n",
    "        # predictions_train = np.sign(variational_classifier(weights, bias, feats_train.T))\n",
    "        # predictions_val = np.sign(variational_classifier(weights, bias, feats_val.T))\n",
    "        \n",
    "        predictions_train = torch.sign(variational_classifier(weights, bias, feats_train.T))\n",
    "        predictions_val = torch.sign(variational_classifier(weights, bias, feats_val.T))\n",
    "\n",
    "        # Compute accuracy on train and validation set\n",
    "        acc_train = accuracy(Y_train, predictions_train)\n",
    "        acc_val = accuracy(Y_val, predictions_val)\n",
    "\n",
    "        if (it + 1) % opt_steps == 0:\n",
    "            _cost = cost(weights, bias, features, Y)\n",
    "            print(\n",
    "                f\"Iter: {it + 1:5d} | Cost: {_cost:0.7f} | \"\n",
    "                f\"Acc train: {acc_train:0.7f} | Acc validation: {acc_val:0.7f}\"\n",
    "            )\n",
    "\n",
    "    # Compute predictions on validation set\n",
    "    # predictions_val = np.sign(variational_classifier(weights, bias, feats_val.T))\n",
    "    # acc_val = accuracy(clusters_val, predictions_val)\n",
    "    # print(\"accuracy: \", acc_val)\n",
    "    \n",
    "    # Ensure that acc_val is a scalar\n",
    "    acc_val = float(acc_val)\n",
    "\n",
    "    # Return the negative validation accuracy\n",
    "    return -acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "599304a8-d6de-4a24-8f7f-01dddaf11ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_qubits:  4  num layers:  5  learning rate:  0.08721510558604813  opt_steps:  18\n",
      "Iter:    18 | Cost: 0.8794990 | Acc train: 0.6183333 | Acc validation: 0.6175000\n",
      "num_qubits:  4  num layers:  4  learning rate:  0.036778114589002514  opt_steps:  6\n",
      "Iter:     6 | Cost: 1.0149202 | Acc train: 0.5583333 | Acc validation: 0.5700000\n",
      "num_qubits:  3  num layers:  4  learning rate:  0.08309518558979441  opt_steps:  12\n",
      "Iter:    12 | Cost: 0.8926169 | Acc train: 0.5808333 | Acc validation: 0.5675000\n",
      "num_qubits:  4  num layers:  5  learning rate:  0.04036565443755416  opt_steps:  15\n",
      "Iter:    15 | Cost: 0.9083252 | Acc train: 0.6066667 | Acc validation: 0.6100000\n",
      "num_qubits:  3  num layers:  6  learning rate:  0.02263157023713807  opt_steps:  18\n",
      "Iter:    18 | Cost: 0.9726591 | Acc train: 0.6641667 | Acc validation: 0.6900000\n",
      "num_qubits:  4  num layers:  5  learning rate:  0.05684297315960845  opt_steps:  15\n",
      "Iter:    15 | Cost: 0.8841655 | Acc train: 0.7066666 | Acc validation: 0.6975000\n",
      "num_qubits:  5  num layers:  4  learning rate:  0.058363590650410975  opt_steps:  16\n",
      "Iter:    16 | Cost: 0.9561454 | Acc train: 0.5383334 | Acc validation: 0.5375000\n",
      "num_qubits:  2  num layers:  4  learning rate:  0.026769910899408403  opt_steps:  16\n",
      "Iter:    16 | Cost: 1.0105884 | Acc train: 0.5175000 | Acc validation: 0.5150000\n",
      "num_qubits:  3  num layers:  3  learning rate:  0.039172690701389276  opt_steps:  7\n",
      "Iter:     7 | Cost: 1.0095558 | Acc train: 0.5108333 | Acc validation: 0.5050000\n",
      "num_qubits:  3  num layers:  4  learning rate:  0.09123386279764645  opt_steps:  12\n",
      "Iter:    12 | Cost: 0.8776359 | Acc train: 0.6375000 | Acc validation: 0.6375000\n",
      "num_qubits:  6  num layers:  6  learning rate:  0.1  opt_steps:  9\n",
      "Iter:     9 | Cost: 0.8983356 | Acc train: 0.5808333 | Acc validation: 0.5750000\n",
      "num_qubits:  5  num layers:  6  learning rate:  0.01  opt_steps:  6\n",
      "Iter:     6 | Cost: 1.1215248 | Acc train: 0.4166667 | Acc validation: 0.4375000\n",
      "num_qubits:  3  num layers:  6  learning rate:  0.06866710027948855  opt_steps:  16\n",
      "Iter:    16 | Cost: 0.8891568 | Acc train: 0.5866666 | Acc validation: 0.5725000\n",
      "num_qubits:  3  num layers:  2  learning rate:  0.011524876940730957  opt_steps:  18\n",
      "Iter:    18 | Cost: 1.0230259 | Acc train: 0.6108333 | Acc validation: 0.6350000\n",
      "num_qubits:  4  num layers:  5  learning rate:  0.0710039981640018  opt_steps:  14\n",
      "Iter:    14 | Cost: 0.8666558 | Acc train: 0.6050000 | Acc validation: 0.6100000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.016525533779106944  opt_steps:  19\n",
      "Iter:    19 | Cost: 0.9577698 | Acc train: 0.6591667 | Acc validation: 0.6675000\n",
      "num_qubits:  6  num layers:  2  learning rate:  0.09807508193859835  opt_steps:  19\n",
      "Iter:    19 | Cost: 0.9842639 | Acc train: 0.6091667 | Acc validation: 0.6050000\n",
      "num_qubits:  3  num layers:  6  learning rate:  0.01  opt_steps:  20\n",
      "Iter:    20 | Cost: 1.0048386 | Acc train: 0.5408334 | Acc validation: 0.5375000\n",
      "num_qubits:  6  num layers:  2  learning rate:  0.015325892053535219  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0226954 | Acc train: 0.6008334 | Acc validation: 0.6200000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.029463906498346543  opt_steps:  18\n",
      "Iter:    18 | Cost: 0.9514263 | Acc train: 0.7100000 | Acc validation: 0.7175000\n",
      "num_qubits:  2  num layers:  5  learning rate:  0.032566212235603735  opt_steps:  18\n",
      "Iter:    18 | Cost: 0.9243699 | Acc train: 0.5541667 | Acc validation: 0.5700000\n",
      "num_qubits:  6  num layers:  2  learning rate:  0.011592888869680035  opt_steps:  11\n",
      "Iter:    11 | Cost: 1.0855712 | Acc train: 0.4450000 | Acc validation: 0.4800000\n",
      "num_qubits:  6  num layers:  2  learning rate:  0.09719621260366336  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.9428825 | Acc train: 0.5833333 | Acc validation: 0.5625000\n",
      "num_qubits:  6  num layers:  6  learning rate:  0.019271216833838034  opt_steps:  17\n",
      "Iter:    17 | Cost: 0.9754325 | Acc train: 0.5141667 | Acc validation: 0.5175000\n",
      "num_qubits:  6  num layers:  2  learning rate:  0.09239860697045502  opt_steps:  15\n",
      "Iter:    15 | Cost: 0.9467272 | Acc train: 0.6050000 | Acc validation: 0.6150000\n",
      "num_qubits:  6  num layers:  6  learning rate:  0.01739075236737894  opt_steps:  18\n",
      "Iter:    18 | Cost: 0.9736696 | Acc train: 0.5300000 | Acc validation: 0.5325000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.013093695374535329  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0428085 | Acc train: 0.6766667 | Acc validation: 0.6850000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.0297665170924568  opt_steps:  16\n",
      "Iter:    16 | Cost: 0.9862218 | Acc train: 0.5583333 | Acc validation: 0.5650000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.010571505951354506  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0601676 | Acc train: 0.6441666 | Acc validation: 0.6850000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.021842655234862913  opt_steps:  14\n",
      "Iter:    14 | Cost: 0.9968463 | Acc train: 0.5316667 | Acc validation: 0.5275000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.0988262818105156  opt_steps:  13\n",
      "Iter:    13 | Cost: 0.8962291 | Acc train: 0.6241667 | Acc validation: 0.6100000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.011897820594499366  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0433999 | Acc train: 0.7000000 | Acc validation: 0.7600000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.011837687383209072  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0451055 | Acc train: 0.7041667 | Acc validation: 0.7475000\n",
      "num_qubits:  2  num layers:  3  learning rate:  0.011873106354781199  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0380125 | Acc train: 0.5900000 | Acc validation: 0.6050000\n",
      "num_qubits:  2  num layers:  5  learning rate:  0.1  opt_steps:  15\n",
      "Iter:    15 | Cost: 0.8817983 | Acc train: 0.6750000 | Acc validation: 0.6425000\n",
      "num_qubits:  2  num layers:  5  learning rate:  0.010125955502308647  opt_steps:  20\n",
      "Iter:    20 | Cost: 1.0092393 | Acc train: 0.5425000 | Acc validation: 0.5425000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.09325166894380435  opt_steps:  5\n",
      "Iter:     5 | Cost: 1.0369856 | Acc train: 0.5116667 | Acc validation: 0.5100000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.08324754312388805  opt_steps:  13\n",
      "Iter:    13 | Cost: 0.9290401 | Acc train: 0.6083333 | Acc validation: 0.6500000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.1  opt_steps:  18\n",
      "Iter:    18 | Cost: 0.8808231 | Acc train: 0.6833333 | Acc validation: 0.7075000\n",
      "num_qubits:  4  num layers:  6  learning rate:  0.0810860415430903  opt_steps:  19\n",
      "Iter:    19 | Cost: 0.8618259 | Acc train: 0.6333333 | Acc validation: 0.6250000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.01  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0698017 | Acc train: 0.5833333 | Acc validation: 0.6200000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.09359626701383669  opt_steps:  10\n",
      "Iter:    10 | Cost: 1.0010861 | Acc train: 0.5383334 | Acc validation: 0.5250000\n",
      "num_qubits:  4  num layers:  5  learning rate:  0.08396671240406628  opt_steps:  16\n",
      "Iter:    16 | Cost: 0.8863444 | Acc train: 0.6325000 | Acc validation: 0.6475000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.010544652262942425  opt_steps:  12\n",
      "Iter:    12 | Cost: 1.0751009 | Acc train: 0.5450000 | Acc validation: 0.5775000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.017523073848708572  opt_steps:  18\n",
      "Iter:    18 | Cost: 0.9914790 | Acc train: 0.5466667 | Acc validation: 0.5525000\n",
      "num_qubits:  6  num layers:  2  learning rate:  0.01  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0771412 | Acc train: 0.5358334 | Acc validation: 0.5575000\n",
      "num_qubits:  6  num layers:  2  learning rate:  0.011210365243678156  opt_steps:  8\n",
      "Iter:     8 | Cost: 1.1186255 | Acc train: 0.4166667 | Acc validation: 0.4400000\n",
      "num_qubits:  6  num layers:  5  learning rate:  0.09898822403602708  opt_steps:  14\n",
      "Iter:    14 | Cost: 0.8750243 | Acc train: 0.5850000 | Acc validation: 0.5750000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.028262147422752862  opt_steps:  18\n",
      "Iter:    18 | Cost: 0.9585211 | Acc train: 0.6266667 | Acc validation: 0.6375000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.06696252383189442  opt_steps:  19\n",
      "Iter:    19 | Cost: 0.8903026 | Acc train: 0.6408333 | Acc validation: 0.6450000\n",
      "num_qubits:  2  num layers:  4  learning rate:  0.01  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0564623 | Acc train: 0.6175000 | Acc validation: 0.6500000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.1  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0083159 | Acc train: 0.6000000 | Acc validation: 0.6250000\n",
      "num_qubits:  2  num layers:  3  learning rate:  0.1  opt_steps:  19\n",
      "Iter:    19 | Cost: 0.8567744 | Acc train: 0.5966667 | Acc validation: 0.6025000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.01  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0227699 | Acc train: 0.6100000 | Acc validation: 0.6125000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.012927653421356692  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0345140 | Acc train: 0.6666667 | Acc validation: 0.7050000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.09902259024858914  opt_steps:  9\n",
      "Iter:     9 | Cost: 0.9925436 | Acc train: 0.5191666 | Acc validation: 0.5125000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.09946945665662264  opt_steps:  17\n",
      "Iter:    17 | Cost: 0.9251992 | Acc train: 0.6058334 | Acc validation: 0.5950000\n",
      "num_qubits:  6  num layers:  6  learning rate:  0.01195059372214962  opt_steps:  5\n",
      "Iter:     5 | Cost: 1.1456174 | Acc train: 0.4166667 | Acc validation: 0.4375000\n",
      "num_qubits:  6  num layers:  5  learning rate:  0.010538957143121438  opt_steps:  15\n",
      "Iter:    15 | Cost: 1.0172035 | Acc train: 0.5716667 | Acc validation: 0.5850000\n",
      "num_qubits:  2  num layers:  3  learning rate:  0.09797875341766496  opt_steps:  14\n",
      "Iter:    14 | Cost: 0.9047179 | Acc train: 0.7066666 | Acc validation: 0.7000000\n",
      "num_qubits:  6  num layers:  6  learning rate:  0.023992398191310625  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.9302281 | Acc train: 0.7116666 | Acc validation: 0.7275000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.011867055579827075  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0466714 | Acc train: 0.7033333 | Acc validation: 0.7450000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.1  opt_steps:  14\n",
      "Iter:    14 | Cost: 0.9196041 | Acc train: 0.6316667 | Acc validation: 0.6625000\n",
      "num_qubits:  6  num layers:  6  learning rate:  0.011620011314051867  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.9881513 | Acc train: 0.5441667 | Acc validation: 0.5475000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.09176554547961346  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.9064060 | Acc train: 0.7016667 | Acc validation: 0.7100000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.09825564954955383  opt_steps:  14\n",
      "Iter:    14 | Cost: 0.9286223 | Acc train: 0.6533333 | Acc validation: 0.6475000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.09827288417509264  opt_steps:  14\n",
      "Iter:    14 | Cost: 0.9356506 | Acc train: 0.6641667 | Acc validation: 0.6525000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.08846963918988521  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.9839482 | Acc train: 0.5825000 | Acc validation: 0.5875000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.0918497816080217  opt_steps:  14\n",
      "Iter:    14 | Cost: 0.9507171 | Acc train: 0.6100000 | Acc validation: 0.6450000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.09869195305434571  opt_steps:  14\n",
      "Iter:    14 | Cost: 0.9691952 | Acc train: 0.5716667 | Acc validation: 0.5875000\n",
      "num_qubits:  6  num layers:  2  learning rate:  0.09192428699181426  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.9690021 | Acc train: 0.5833333 | Acc validation: 0.5625000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.012166842742958081  opt_steps:  11\n",
      "Iter:    11 | Cost: 1.0649123 | Acc train: 0.6008334 | Acc validation: 0.6375000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.012558937928950936  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0093156 | Acc train: 0.5375000 | Acc validation: 0.5450000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.021847055435048342  opt_steps:  14\n",
      "Iter:    14 | Cost: 0.9970576 | Acc train: 0.5391667 | Acc validation: 0.5325000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.09751448754013702  opt_steps:  13\n",
      "Iter:    13 | Cost: 0.9458008 | Acc train: 0.6200000 | Acc validation: 0.6625000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.018511547930663567  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.9789028 | Acc train: 0.5975000 | Acc validation: 0.6450000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.09248323620926314  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.9583435 | Acc train: 0.5925000 | Acc validation: 0.5925000\n",
      "num_qubits:  6  num layers:  6  learning rate:  0.09936250501265942  opt_steps:  12\n",
      "Iter:    12 | Cost: 0.9005631 | Acc train: 0.6241667 | Acc validation: 0.6400000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.09041898216272858  opt_steps:  5\n",
      "Iter:     5 | Cost: 1.0700297 | Acc train: 0.5133333 | Acc validation: 0.5000000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.012171626384973672  opt_steps:  14\n",
      "Iter:    14 | Cost: 1.0369880 | Acc train: 0.6775000 | Acc validation: 0.7125000\n",
      "num_qubits:  6  num layers:  6  learning rate:  0.09100834488329893  opt_steps:  12\n",
      "Iter:    12 | Cost: 0.8711929 | Acc train: 0.6450000 | Acc validation: 0.6500000\n",
      "num_qubits:  4  num layers:  6  learning rate:  0.026348055426648767  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.9254246 | Acc train: 0.6208333 | Acc validation: 0.6400000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.01201966528659768  opt_steps:  15\n",
      "Iter:    15 | Cost: 1.0263027 | Acc train: 0.6500000 | Acc validation: 0.6775000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.05383920379864264  opt_steps:  13\n",
      "Iter:    13 | Cost: 0.8891159 | Acc train: 0.6358333 | Acc validation: 0.6625000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.0941856317975394  opt_steps:  17\n",
      "Iter:    17 | Cost: 0.8894727 | Acc train: 0.5833333 | Acc validation: 0.5625000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.02344908112178945  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.9860238 | Acc train: 0.5225000 | Acc validation: 0.5300000\n",
      "num_qubits:  3  num layers:  2  learning rate:  0.012201238439241863  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0447046 | Acc train: 0.6833333 | Acc validation: 0.7050000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.0910300751644084  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.8806512 | Acc train: 0.6475000 | Acc validation: 0.6125000\n",
      "num_qubits:  6  num layers:  6  learning rate:  0.023924169250031956  opt_steps:  19\n",
      "Iter:    19 | Cost: 0.9501569 | Acc train: 0.5983334 | Acc validation: 0.6175000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.013587287021650938  opt_steps:  14\n",
      "Iter:    14 | Cost: 1.0243986 | Acc train: 0.6408333 | Acc validation: 0.6600000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.011721249771997505  opt_steps:  14\n",
      "Iter:    14 | Cost: 1.0409420 | Acc train: 0.6900000 | Acc validation: 0.7350000\n",
      "num_qubits:  3  num layers:  2  learning rate:  0.01113457206963571  opt_steps:  14\n",
      "Iter:    14 | Cost: 1.0492592 | Acc train: 0.7000000 | Acc validation: 0.7325000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.011622720342001172  opt_steps:  14\n",
      "Iter:    14 | Cost: 1.0435743 | Acc train: 0.6958333 | Acc validation: 0.7425000\n",
      "num_qubits:  2  num layers:  6  learning rate:  0.02964761105464147  opt_steps:  19\n",
      "Iter:    19 | Cost: 0.9821284 | Acc train: 0.5425000 | Acc validation: 0.5850000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.011629576597819598  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0493721 | Acc train: 0.7075000 | Acc validation: 0.7625000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.011269895287451115  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0533049 | Acc train: 0.6708333 | Acc validation: 0.7275000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.01160876896364938  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0468194 | Acc train: 0.6975000 | Acc validation: 0.7425000\n",
      "num_qubits:  6  num layers:  6  learning rate:  0.02471340558213953  opt_steps:  20\n",
      "Iter:    20 | Cost: 0.9279575 | Acc train: 0.6741667 | Acc validation: 0.6850000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.09732439532950395  opt_steps:  14\n",
      "Iter:    14 | Cost: 0.9671476 | Acc train: 0.5833333 | Acc validation: 0.6125000\n",
      "num_qubits:  2  num layers:  2  learning rate:  0.011552051604119241  opt_steps:  13\n",
      "Iter:    13 | Cost: 1.0542129 | Acc train: 0.6908333 | Acc validation: 0.7500000\n",
      "Best accuracy: 0.762499988079071\n",
      "Best parameters: [2, 2, 0.011629576597819598, 13]\n"
     ]
    }
   ],
   "source": [
    "# Define the search space\n",
    "space  = [Integer(2, 6, name='num_qubits'), Integer(2, 6, name='num_layers'), Real(0.01, 0.1, name='learning_rate'), Integer(5, 20, name='opt_steps')]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "res_gp = gp_minimize(objective, space, n_calls=15, random_state=0)\n",
    "\n",
    "print(f\"Best accuracy: {-res_gp.fun}\") \n",
    "print(f\"Best parameters: {res_gp.x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f66242-3f45-4a6f-be8d-c79091df933b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
