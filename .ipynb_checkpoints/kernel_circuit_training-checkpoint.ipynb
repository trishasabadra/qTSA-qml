{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://pennylane.ai/qml/demos/tutorial_kernel_based_training/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is added by sphinx-gallery\n",
    "# It can be customized to whatever you like\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel-based training\n",
    "====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pennylane as qml\n",
    "from pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(x, y):\n",
    "    # Combine X_train and y_train for simultaneous shuffling\n",
    "    combined_data = np.column_stack((x, y))\n",
    "    \n",
    "    # Shuffle the combined data along the first axis\n",
    "    np.random.shuffle(combined_data)\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN DATA\n",
    "X_train = np.loadtxt(\"trainX.txt\") # size 1600\n",
    "y_train = np.loadtxt(\"trainY.txt\")\n",
    "X_test = np.loadtxt(\"testX.txt\") # size 256\n",
    "y_test = np.loadtxt(\"testY.txt\")\n",
    "\n",
    "train_data = shuffle_data(X_train, y_train)\n",
    "# Separate shuffled X_train and y_train back into individual arrays\n",
    "X_train = train_data[:, :-1]\n",
    "y_train = train_data[:, -1]\n",
    "\n",
    "test_data = shuffle_data(X_test, y_test)\n",
    "X_test = test_data[:, :-1]\n",
    "y_test = test_data[:, -1]\n",
    "\n",
    "# X_train = X_train[:200]\n",
    "# y_train = y_train[:200]\n",
    "# X_test = X_test[:200]\n",
    "# y_test = y_test[:200]\n",
    "\n",
    "# scaling the inputs is important since the embedding we use is periodic\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "scaler = StandardScaler().fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# swaps 0 with -1 so we classify by -1 and 1 instead of 0 and 1\n",
    "y_train = np.where(y_train == 0, -1.0, 1.0) \n",
    "y_test = np.where(y_test == 0, -1.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [angle-embedding\n",
    "template](https://pennylane.readthedocs.io/en/stable/code/api/pennylane.templates.embeddings.AngleEmbedding.html)\n",
    "which needs as many qubits as there are features:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the kernel we could prepare the two states\n",
    "$| \\phi(x) \\rangle$, $| \\phi(x') \\rangle$ on different sets of qubits\n",
    "with angle-embedding routines $S(x), S(x')$, and measure their overlap\n",
    "with a small routine called a [SWAP\n",
    "test](https://en.wikipedia.org/wiki/Swap_test).\n",
    "\n",
    "However, we need only half the number of qubits if we prepare\n",
    "$| \\phi(x)\\rangle$ and then apply the inverse embedding with $x'$ on the\n",
    "same qubits. We then measure the projector onto the initial state\n",
    "$|0..0\\rangle \\langle 0..0|$.\n",
    "\n",
    "![](../_static/demonstration_assets/kernel_based_training/kernel_circuit.png){.align-center}\n",
    "\n",
    "To verify that this gives us the kernel:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\begin{align*}\n",
    "    \\langle 0..0 |S(x') S(x)^{\\dagger} \\mathcal{M} S(x')^{\\dagger} S(x)  | 0..0\\rangle &= \\langle 0..0 |S(x') S(x)^{\\dagger} |0..0\\rangle \\langle 0..0| S(x')^{\\dagger} S(x)  | 0..0\\rangle  \\\\\n",
    "    &= |\\langle 0..0| S(x')^{\\dagger} S(x)  | 0..0\\rangle |^2\\\\\n",
    "    &= | \\langle \\phi(x') | \\phi(x)\\rangle|^2 \\\\\n",
    "    &= \\kappa(x, x').\n",
    "\\end{align*}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Note that a projector $|0..0 \\rangle \\langle 0..0|$ can be constructed\n",
    "using the `qml.Hermitian` observable in PennyLane.\n",
    "\n",
    "Altogether, we use the following quantum node as a *quantum kernel\n",
    "evaluator*:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "n_qubits = 6\n",
    "dev_kernel = qml.device(\"qiskit.aer\", wires=n_qubits)\n",
    "\n",
    "projector = np.zeros((2 ** n_qubits, 2 ** n_qubits)) # matrix is used in the measurement step to extract the expectation value\n",
    "projector[0, 0] = 1\n",
    "\n",
    "@qml.qnode(dev_kernel)\n",
    "def kernel(x1, x2):\n",
    "    \"\"\"The quantum kernel.\"\"\"\n",
    "    AngleEmbedding(x1, wires=range(n_qubits)) # encodes classical data x1 into quantum states using rotation gate RX\n",
    "    qml.adjoint(AngleEmbedding)(x2, wires=range(n_qubits)) # adjoint of an operation is it's inverse -> inverses the rotation -> \"uncomputes\" the state from x2 -> allows to measure overlap\n",
    "    return qml.expval(qml.Hermitian(projector, wires=range(n_qubits))) # measures the overlap between the quantum states x1 and x2\n",
    "\n",
    "# angle embedding circuit looks like:\n",
    "#                 inverse of RX\n",
    "# 0: ──RX(x1[0])───RX†(x2[0])───┤ <Hermitian Measurement>\n",
    "# 1: ──RX(x1[1])───RX†(x2[1])───┤ <Hermitian Measurement>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_kernel._circuit.draw(output='mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good sanity check is whether evaluating the kernel of a data point and\n",
    "itself returns 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel(X_train[0], X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way an SVM with a custom kernel is implemented in scikit-learn\n",
    "requires us to pass a function that computes a matrix of kernel\n",
    "evaluations for samples in two different datasets A, B. If A=B, this is\n",
    "the [Gram matrix](https://en.wikipedia.org/wiki/Gramian_matrix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def kernel_matrix(A, B):\n",
    "    \"\"\"Compute the matrix whose entries are the kernel\n",
    "       evaluated on pairwise data from sets A and B.\"\"\"\n",
    "    return np.array([[kernel(a, b) for b in B] for a in A])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the SVM optimizes internal parameters that basically weigh\n",
    "kernel functions. It is a breeze in scikit-learn, which is designed as a\n",
    "high-level machine learning library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "svm = SVC(kernel=kernel_matrix).fit(X_train, y_train) # try probability=True? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "# accuracy on training data\n",
    "with dev_kernel.tracker:\n",
    "    predictions = svm.predict(X_train)\n",
    "    print(accuracy_score(predictions, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "# accuracy on test data\n",
    "with dev_kernel.tracker:\n",
    "    predictions = svm.predict(X_test)\n",
    "    print(accuracy_score(predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size 200: 0.92 training accuracy, 0.85 testing\n",
    "# tried 2 and 3 qubits but had exact same result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM predicted all test points correctly. How many times was the\n",
    "quantum device evaluated?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_kernel.tracker.totals['executions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number can be derived as follows: For $M$ training samples, the SVM\n",
    "must construct the $M \\times M$ dimensional kernel gram matrix for\n",
    "training. To classify $M_{\\rm pred}$ new samples, the SVM needs to\n",
    "evaluate the kernel at most $M_{\\rm pred}M$ times to get the pairwise\n",
    "distances between training vectors and test samples.\n",
    "\n",
    "Depending on the implementation of the SVM, only $S \\leq M_{\\rm pred}$\n",
    "*support vectors* are needed.\n",
    "\n",
    "Let us formulate this as a function, which can be used at the end of the\n",
    "demo to construct the scaling plot shown in the introduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def circuit_evals_kernel(n_data, split):\n",
    "    \"\"\"Compute how many circuit evaluations one needs for kernel-based\n",
    "       training and prediction.\"\"\"\n",
    "\n",
    "    M = int(np.ceil(split * n_data))\n",
    "    Mpred = n_data - M\n",
    "\n",
    "    n_training = M * M\n",
    "    n_prediction = M * Mpred\n",
    "\n",
    "    return n_training + n_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $M = 75$ and $M_{\\rm pred} = 25$, the number of kernel evaluations\n",
    "can therefore be estimated as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit_evals_kernel(n_data=len(X), split=len(X_train) / (len(X_train) + len(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
