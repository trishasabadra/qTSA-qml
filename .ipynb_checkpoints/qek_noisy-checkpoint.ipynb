{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://pennylane.ai/qml/demos/tutorial_kernels_module/\n",
    "# evaluate kernels, use them for classification and train them with gradient-based optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pennylane import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA \n",
    "X_full = np.loadtxt(\"trainX.txt\")\n",
    "Y_full = np.loadtxt(\"trainY.txt\")\n",
    "\n",
    "X = X_full[:400]\n",
    "Y = Y_full[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "from qiskit_aer import noise\n",
    "\n",
    "# Error probabilities\n",
    "prob_1 = 0.001  # 1-qubit gate\n",
    "prob_2 = 0.01   # 2-qubit gate\n",
    "\n",
    "# Depolarizing quantum errors\n",
    "error_1 = noise.depolarizing_error(prob_1, 1)\n",
    "error_2 = noise.depolarizing_error(prob_2, 2)\n",
    "\n",
    "# Add errors to noise model\n",
    "noise_model = noise.NoiseModel()\n",
    "noise_model.add_all_qubit_quantum_error(error_1, ['u1', 'u2', 'u3'])\n",
    "noise_model.add_all_qubit_quantum_error(error_2, ['cx'])\n",
    "\n",
    "# Create a PennyLane device\n",
    "dev = qml.device('qiskit.aer', wires=4, noise_model=noise_model)\n",
    "wires = dev.wires.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def layer(x, params, wires, i0=0, inc=1):\n",
    "    \"\"\"Building block of the embedding ansatz\"\"\"\n",
    "    i = i0\n",
    "    for j, wire in enumerate(wires):\n",
    "        qml.Hadamard(wires=[wire])\n",
    "        qml.RZ(x[i % len(x)], wires=[wire])\n",
    "        i += inc\n",
    "        qml.RY(params[0][j], wires=[wire])\n",
    "        # qml.RY(params[0, j], wires=[wire])\n",
    "\n",
    "    qml.broadcast(unitary=qml.CRZ, pattern=\"ring\", wires=wires, parameters=params[1])\n",
    "\n",
    "def ansatz(x, params, wires):\n",
    "    \"\"\"The embedding ansatz\"\"\"\n",
    "    for j, layer_params in enumerate(params):\n",
    "        layer(x, layer_params, wires, i0=j * len(wires))\n",
    "\n",
    "\n",
    "adjoint_ansatz = qml.adjoint(ansatz)\n",
    "\n",
    "\n",
    "def random_params(num_wires, num_layers):\n",
    "    \"\"\"Generate random variational parameters in the shape for the ansatz.\"\"\"\n",
    "    return np.random.uniform(0, 2 * np.pi, (num_layers, 2, num_wires), requires_grad=True)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def kernel_circuit(x1, x2, params):\n",
    "    ansatz(x1, params, wires=wires)\n",
    "    adjoint_ansatz(x2, params, wires=wires)\n",
    "    return qml.probs(wires=wires)\n",
    "\n",
    "def kernel(x1, x2, params):\n",
    "    return kernel_circuit(x1, x2, params)[0] # kernel value = probabality of |000> (all-zero state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(classifier, X, Y_target):\n",
    "    return 1 - np.count_nonzero(classifier.predict(X) - Y_target) / len(Y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pennylane.optimize import AdamOptimizer\n",
    "\n",
    "def target_alignment( X, Y, kernel, assume_normalized_kernel=False, rescale_class_labels=True,):\n",
    "    \"\"\"Kernel-target alignment between kernel and labels.\"\"\"\n",
    "\n",
    "    # calculate kernel matrix K\n",
    "    K = qml.kernels.square_kernel_matrix(\n",
    "        X,\n",
    "        kernel,\n",
    "        assume_normalized_kernel=assume_normalized_kernel,\n",
    "    )\n",
    "\n",
    "    if rescale_class_labels:\n",
    "        nplus = np.count_nonzero(np.array(Y) == 1)\n",
    "        nminus = len(Y) - nplus\n",
    "        _Y = np.array([y / nplus if y == 1 else y / nminus for y in Y])\n",
    "    else:\n",
    "        _Y = np.array(Y)\n",
    "\n",
    "    # calculate target matrix T\n",
    "    T = np.outer(_Y, _Y)\n",
    "    inner_product = np.sum(K * T)\n",
    "    norm = np.sqrt(np.sum(K * K) * np.sum(T * T))\n",
    "\n",
    "    # Check if norm is zero to avoid division by zero\n",
    "    if norm == 0:\n",
    "        return inner_product\n",
    "    \n",
    "    inner_product = inner_product / norm\n",
    "\n",
    "    return inner_product\n",
    "\n",
    "params = random_params(num_wires=4, num_layers=6)\n",
    "opt = qml.AdamOptimizer(0.01)\n",
    "batch_size = 4\n",
    "\n",
    "for i in range(250):\n",
    "    # Choose subset of datapoints to compute the KTA on.\n",
    "    subset = np.random.choice(list(range(len(X))), batch_size)\n",
    "    # Define the cost function for optimization\n",
    "    cost = lambda _params: -target_alignment(\n",
    "        X[subset],\n",
    "        Y[subset],\n",
    "        lambda x1, x2: kernel(x1, x2, _params),\n",
    "        assume_normalized_kernel=True,\n",
    "    )\n",
    "    # Optimization step\n",
    "    params = opt.step(cost, params)\n",
    "\n",
    "    # Report the alignment on the full dataset every 50 steps.\n",
    "    if (i + 1) % 25 == 0:\n",
    "        current_alignment = target_alignment(\n",
    "            X,\n",
    "            Y,\n",
    "            lambda x1, x2: kernel(x1, x2, params),\n",
    "            assume_normalized_kernel=True,\n",
    "        )\n",
    "        print(f\"Step {i+1} - Alignment = {current_alignment:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimized paramters: \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parameters must contain entries for 1 unitaries; got 5 entries",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m trained_kernel_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m X1, X2: qml\u001b[38;5;241m.\u001b[39mkernels\u001b[38;5;241m.\u001b[39mkernel_matrix(X1, X2, trained_kernel)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Note that SVC expects the kernel argument to be a kernel matrix function.\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m svm_trained \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39mtrained_kernel_matrix)\u001b[38;5;241m.\u001b[39mfit(X, Y)\n\u001b[1;32m     13\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime in min: \u001b[39m\u001b[38;5;124m\"\u001b[39m, (end\u001b[38;5;241m-\u001b[39mstart)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/sklearn/svm/_base.py:309\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;66;03m# you must store a reference to X to compute the kernel in predict\u001b[39;00m\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;66;03m# TODO: add keyword copy to copy on demand\u001b[39;00m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__Xfit \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m--> 309\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_kernel(X)\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[0] should be equal to X.shape[1]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/sklearn/svm/_base.py:507\u001b[0m, in \u001b[0;36mBaseLibSVM._compute_kernel\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the data transformed by a callable kernel\"\"\"\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# in the case of precomputed kernel given as a function, we\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# have to compute explicitly the kernel matrix\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__Xfit)\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(kernel):\n\u001b[1;32m    509\u001b[0m         kernel \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "Cell \u001b[0;32mIn[37], line 8\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(X1, X2)\u001b[0m\n\u001b[1;32m      5\u001b[0m trained_kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x1, x2: kernel(x1, x2, params)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Second create a kernel matrix function using the trained kernel.\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m trained_kernel_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m X1, X2: qml\u001b[38;5;241m.\u001b[39mkernels\u001b[38;5;241m.\u001b[39mkernel_matrix(X1, X2, trained_kernel)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Note that SVC expects the kernel argument to be a kernel matrix function.\u001b[39;00m\n\u001b[1;32m     11\u001b[0m svm_trained \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39mtrained_kernel_matrix)\u001b[38;5;241m.\u001b[39mfit(X, Y)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/pennylane/kernels/utils.py:132\u001b[0m, in \u001b[0;36mkernel_matrix\u001b[0;34m(X1, X2, kernel)\u001b[0m\n\u001b[1;32m    129\u001b[0m N \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mshape(X1)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    130\u001b[0m M \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mshape(X2)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 132\u001b[0m matrix \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mstack([kernel(x, y) \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m product(X1, X2)])\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mndim(matrix[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreshape(matrix, (N, M))\n",
      "Cell \u001b[0;32mIn[37], line 5\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# First create a kernel with the trained parameter baked into it.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m trained_kernel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x1, x2: kernel(x1, x2, params)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Second create a kernel matrix function using the trained kernel.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m trained_kernel_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m X1, X2: qml\u001b[38;5;241m.\u001b[39mkernels\u001b[38;5;241m.\u001b[39mkernel_matrix(X1, X2, trained_kernel)\n",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m, in \u001b[0;36mkernel\u001b[0;34m(x1, x2, params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkernel\u001b[39m(x1, x2, params):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m kernel_circuit(x1, x2, params)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/pennylane/workflow/qnode.py:1092\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     override_shots \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshots\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;66;03m# construct the tape\u001b[39;00m\n\u001b[0;32m-> 1092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstruct(args, kwargs)\n\u001b[1;32m   1094\u001b[0m original_grad_fn \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_fn, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice]\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_gradient_fn(shots\u001b[38;5;241m=\u001b[39moverride_shots, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/pennylane/workflow/qnode.py:929\u001b[0m, in \u001b[0;36mQNode.construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;241m=\u001b[39m qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mget_interface(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mqueuing\u001b[38;5;241m.\u001b[39mAnnotatedQueue() \u001b[38;5;28;01mas\u001b[39;00m q:\n\u001b[0;32m--> 929\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qfunc_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    931\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape \u001b[38;5;241m=\u001b[39m QuantumScript\u001b[38;5;241m.\u001b[39mfrom_queue(q, shots)\n\u001b[1;32m    933\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtape\u001b[38;5;241m.\u001b[39mget_parameters(trainable_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m, in \u001b[0;36mkernel_circuit\u001b[0;34m(x1, x2, params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@qml\u001b[39m\u001b[38;5;241m.\u001b[39mqnode(dev)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkernel_circuit\u001b[39m(x1, x2, params):\n\u001b[0;32m----> 3\u001b[0m     ansatz(x1, params, wires\u001b[38;5;241m=\u001b[39mwires)\n\u001b[1;32m      4\u001b[0m     adjoint_ansatz(x2, params, wires\u001b[38;5;241m=\u001b[39mwires)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m qml\u001b[38;5;241m.\u001b[39mprobs(wires\u001b[38;5;241m=\u001b[39mwires)\n",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m, in \u001b[0;36mansatz\u001b[0;34m(x, params, wires)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"The embedding ansatz\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, layer_params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(params):\n\u001b[0;32m----> 4\u001b[0m     layer(x, layer_params, wires, i0\u001b[38;5;241m=\u001b[39mj \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(wires))\n",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m, in \u001b[0;36mlayer\u001b[0;34m(x, params, wires, i0, inc)\u001b[0m\n\u001b[1;32m     10\u001b[0m     qml\u001b[38;5;241m.\u001b[39mRY(params[\u001b[38;5;241m0\u001b[39m, j], wires\u001b[38;5;241m=\u001b[39m[wire])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# qml.broadcast(unitary=qml.CRZ, pattern=\"ring\", wires=wires, parameters=params[1])\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m qml\u001b[38;5;241m.\u001b[39mbroadcast(unitary\u001b[38;5;241m=\u001b[39mqml\u001b[38;5;241m.\u001b[39mCRZ, pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchain\u001b[39m\u001b[38;5;124m\"\u001b[39m, wires\u001b[38;5;241m=\u001b[39mwires, parameters\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/pennylane/templates/broadcast.py:560\u001b[0m, in \u001b[0;36mbroadcast\u001b[0;34m(unitary, wires, pattern, parameters, kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 560\u001b[0m wire_sequence, parameters \u001b[38;5;241m=\u001b[39m _preprocess(parameters, pattern, wires)\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(wire_sequence)):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/pennylane/templates/broadcast.py:132\u001b[0m, in \u001b[0;36m_preprocess\u001b[0;34m(parameters, pattern, wires)\u001b[0m\n\u001b[1;32m    130\u001b[0m     num_params \u001b[38;5;241m=\u001b[39m PATTERN_TO_NUM_PARAMS[pattern](_wires)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m num_params:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    133\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters must contain entries for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m unitaries; got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m entries\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         )\n\u001b[1;32m    136\u001b[0m wire_sequence \u001b[38;5;241m=\u001b[39m PATTERN_TO_WIRES[pattern](_wires)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wire_sequence, parameters\n",
      "\u001b[0;31mValueError\u001b[0m: Parameters must contain entries for 1 unitaries; got 5 entries"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# First create a kernel with the trained parameter baked into it.\n",
    "trained_kernel = lambda x1, x2: kernel(x1, x2, params)\n",
    "\n",
    "# Second create a kernel matrix function using the trained kernel.\n",
    "trained_kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, trained_kernel)\n",
    "\n",
    "# Note that SVC expects the kernel argument to be a kernel matrix function.\n",
    "svm_trained = SVC(kernel=trained_kernel_matrix).fit(X, Y)\n",
    "\n",
    "accuracy_init = accuracy(svm, X, Y)\n",
    "print(f\"The training accuracy of the kernel with optimized parameters on the subset data is {accuracy_init:.3f}\")\n",
    "\n",
    "accuracy_init = accuracy(svm, X_full, Y_full)\n",
    "print(f\"The accuracy on the FULL data is {accuracy_init:.3f}\")\n",
    "\n",
    "end = time.time()\n",
    "print(\"runtime in min: \", (end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST DATA ACCURACY\n",
    "Xtest = np.loadtxt(\"testX.txt\")\n",
    "Ytest = np.loadtxt(\"testY.txt\")\n",
    "accuracy_test = accuracy(svm_trained, Xtest, Ytest)\n",
    "print(f\"The testing accuracy of a kernel with trained parameters is {accuracy_test:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
