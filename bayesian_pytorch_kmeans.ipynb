{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b7b1e-602b-4715-83f7-a504ddaf425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrate pytorch with Bayesian Optimization to potentially improve results - not working yet :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f321702f-d7f2-485b-a896-709fb9ca25d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer, AdamOptimizer\n",
    "from pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n",
    "import matplotlib.pyplot as plt\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Integer, Real\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "dev = qml.device(\"default.qubit\")\n",
    "\n",
    "# Define your data preprocessing functions\n",
    "def get_angles(x):\n",
    "    beta0 = 2 * np.arcsin(np.sqrt(x[1] ** 2) / np.sqrt(x[0] ** 2 + x[1] ** 2 + 1e-12))\n",
    "    beta1 = 2 * np.arcsin(np.sqrt(x[3] ** 2) / np.sqrt(x[2] ** 2 + x[3] ** 2 + 1e-12))\n",
    "    beta2 = 2 * np.arcsin(np.linalg.norm(x[2:]) / np.linalg.norm(x))\n",
    "\n",
    "    # return np.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2])\n",
    "    # return np.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2], dtype=np.float32)\n",
    "    return torch.tensor([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2], dtype=torch.float32)\n",
    "\n",
    "def state_preparation(a):\n",
    "    qml.RY(a[0], wires=0)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[1], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[2], wires=1)\n",
    "\n",
    "    qml.PauliX(wires=0)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[3], wires=1)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.RY(a[4], wires=1)\n",
    "    qml.PauliX(wires=0)\n",
    "\n",
    "def layer(layer_weights):\n",
    "    for wire in range(num_qubits):\n",
    "        qml.Rot(*layer_weights[wire], wires=wire)\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    for i in range(num_qubits): \n",
    "        qml.CZ(wires=[i, (i+1) % num_qubits]) \n",
    "    for i in range(num_qubits): \n",
    "        qml.S(wires=i)  \n",
    "\n",
    "@qml.qnode(dev, interface='torch') # added interface = torch\n",
    "def circuit(weights, x):\n",
    "    state_preparation(x)\n",
    "    for wire in range(num_qubits):\n",
    "        qml.Hadamard(wires=wire)\n",
    "    for layer_weights in weights:\n",
    "        layer(layer_weights)\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    # return np.mean((labels - qml.math.stack(predictions)) ** 2)\n",
    "    # return torch.mean((labels - predictions) ** 2)\n",
    "\n",
    "    print(\"labels: \", labels)\n",
    "    print(\"predictions: \", predictions)\n",
    "    # if (labels.dtype != float):\n",
    "    labels = labels.float()  # Convert to float if necessary\n",
    "    predictions = predictions.float()  # Convert to float if necessary\n",
    "    \n",
    "    # Compute mean squared error\n",
    "    mse = torch.mean((labels - predictions) ** 2)\n",
    "    return mse\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    return acc / len(labels)\n",
    "\n",
    "def cost(weights, bias, X, Y):\n",
    "    predictions = variational_classifier(weights, bias, X.T)\n",
    "    return square_loss(Y, predictions)\n",
    "\n",
    "def load_data(): # Load your data\n",
    "    data = np.loadtxt(\"trainX.txt\")\n",
    "    X = data[:, 0:2]\n",
    "    padding = np.ones((len(X), 2)) * 0.1\n",
    "    X_pad = np.c_[X, padding]\n",
    "    normalization = np.sqrt(np.sum(X_pad**2, -1))\n",
    "    X_norm = (X_pad.T / normalization).T\n",
    "    \n",
    "    features = np.array([get_angles(x) for x in X_norm], requires_grad=False)\n",
    "    # features = torch.tensor([get_angles(x) for x in X_norm], dtype=torch.float32)\n",
    "    # features = [get_angles(x) for x in X_norm]\n",
    "    \n",
    "    Y = np.loadtxt(\"trainY.txt\")\n",
    "    # Y = np.where(Y == 0, -1.0, 1.0)\n",
    "    Y = torch.tensor(np.where(Y == 0, -1.0, 1.0), dtype=torch.float32)\n",
    "\n",
    "# Apply k-means clustering\n",
    "def k_means():\n",
    "    kmeans = KMeans(n_clusters=2, init='k-means++', n_init=10, max_iter=300)\n",
    "    kmeans.fit(X)\n",
    "    clusters = kmeans.labels_\n",
    "    clusters = np.where(clusters == 0, -1.0, 1.0)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "def split_data():\n",
    "    np.random.seed(0)\n",
    "    num_data = len(clusters)\n",
    "    num_train = int(0.75 * num_data)\n",
    "    index = np.random.permutation(range(num_data))\n",
    "    # feats_train = features[index[:num_train]]\n",
    "    # clusters_train = clusters[index[:num_train]]\n",
    "    # feats_val = features[index[num_train:]]\n",
    "    # clusters_val = clusters[index[num_train:]]\n",
    "\n",
    "    # convert to tensor\n",
    "    feats_train = torch.tensor(features[index[:num_train]], dtype=torch.float32)\n",
    "    clusters_train = torch.tensor(clusters[index[:num_train]], dtype=torch.float32)\n",
    "    feats_val = torch.tensor(features[index[num_train:]], dtype=torch.float32)\n",
    "    clusters_val = torch.tensor(clusters[index[num_train:]], dtype=torch.float32)\n",
    "\n",
    "# X_train = X[index[:num_train]]\n",
    "# X_val = X[index[num_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d402eb8c-470e-47b7-95ed-cc503a21fc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Bayesian optimization\n",
    "def objective(params):\n",
    "    global num_qubits\n",
    "    # num_qubits = 2\n",
    "    num_qubits, num_layers, learning_rate, opt_steps = params\n",
    "    opt_steps = int(opt_steps)\n",
    "    num_qubits = int(num_qubits)\n",
    "    num_layers = int(num_layers)\n",
    "\n",
    "    print(\"num_qubits: \", num_qubits, \" num layers: \", num_layers, \" learning rate: \", learning_rate, \" opt_steps: \", opt_steps)\n",
    "\n",
    "    # Initialize variables\n",
    "    # weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "    # bias_init = np.array(0.0, requires_grad=True) \n",
    "    # opt = AdamOptimizer(learning_rate)\n",
    "    \n",
    "    # torch variables\n",
    "    # weights_init = 0.01 * torch.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "    # bias_init = torch.tensor(0.0, requires_grad=True)\n",
    "    weights_init = torch.nn.Parameter(0.01 * torch.randn(num_layers, num_qubits, 3))\n",
    "    bias_init = torch.nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    optimizer = optim.Adam([weights_init, bias_init], lr=learning_rate)\n",
    "    \n",
    "    batch_size = 128\n",
    "\n",
    "    # Train the variational classifier\n",
    "    weights = weights_init\n",
    "    bias = bias_init\n",
    "    acc_val = 0\n",
    "    for it in range(opt_steps):\n",
    "        batch_index = np.random.randint(0, num_train, (batch_size,)) # array of random integers \n",
    "        feats_train_batch = feats_train[batch_index]\n",
    "        clusters_train_batch = clusters_train[batch_index]\n",
    "        \n",
    "        # weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, clusters_train_batch)\n",
    "\n",
    "        # tensor opt step\n",
    "        optimizer.zero_grad()\n",
    "        loss = cost(weights, bias, feats_train_batch, clusters_train_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute predictions on train and validation set\n",
    "        # predictions_train = np.sign(variational_classifier(weights, bias, feats_train.T))\n",
    "        # predictions_val = np.sign(variational_classifier(weights, bias, feats_val.T))\n",
    "        \n",
    "        predictions_train = torch.sign(variational_classifier(weights, bias, feats_train.T))\n",
    "        predictions_val = torch.sign(variational_classifier(weights, bias, feats_val.T))\n",
    "\n",
    "        # Compute accuracy on train and validation set\n",
    "        acc_train = accuracy(clusters_train, predictions_train)\n",
    "        acc_val = accuracy(clusters_val, predictions_val)\n",
    "\n",
    "        if (it + 1) % opt_steps == 0:\n",
    "            _cost = cost(weights, bias, features, clusters)\n",
    "            print(\n",
    "                f\"Iter: {it + 1:5d} | Cost: {_cost:0.7f} | \"\n",
    "                f\"Acc train: {acc_train:0.7f} | Acc validation: {acc_val:0.7f}\"\n",
    "            )\n",
    "\n",
    "    # Compute predictions on validation set\n",
    "    # predictions_val = np.sign(variational_classifier(weights, bias, feats_val.T))\n",
    "    # acc_val = accuracy(clusters_val, predictions_val)\n",
    "    # print(\"accuracy: \", acc_val)\n",
    "    \n",
    "    # Ensure that acc_val is a scalar\n",
    "    acc_val = float(acc_val)\n",
    "\n",
    "    # Return the negative validation accuracy\n",
    "    return -acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "599304a8-d6de-4a24-8f7f-01dddaf11ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_qubits:  4  num layers:  5  learning rate:  0.08721510558604813  opt_steps:  18\n",
      "labels:  tensor([ 1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
      "        -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,\n",
      "        -1.,  1., -1., -1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
      "        -1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,\n",
      "         1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
      "        -1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1.,\n",
      "        -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
      "        -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
      "         1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
      "        -1.,  1.])\n",
      "predictions:  tensor([0.2910, 0.3074, 0.3566, 0.4896, 0.2409, 0.1976, 0.3568, 0.3197, 0.2554,\n",
      "        0.7914, 0.2228, 0.2727, 0.6866, 0.1863, 0.2257, 0.1974, 0.9113, 0.2332,\n",
      "        0.4524, 0.4896, 0.8575, 0.2407, 0.3306, 0.2275, 0.2257, 0.1945, 0.2150,\n",
      "        0.9440, 0.3074, 0.3170, 0.2201, 0.2395, 0.2092, 0.4376, 0.3124, 0.4078,\n",
      "        0.3514, 0.2650, 0.3814, 0.2163, 0.9113, 0.5556, 0.3663, 0.6357, 0.4765,\n",
      "        0.2518, 0.2375, 0.2794, 0.2948, 0.4243, 0.2362, 0.7976, 0.4054, 0.2025,\n",
      "        0.2215, 0.6062, 0.2719, 0.1831, 0.5768, 0.2567, 0.2470, 0.1916, 0.2687,\n",
      "        0.2128, 0.2148, 0.2545, 0.2282, 0.5879, 0.4524, 0.3479, 0.2221, 0.2228,\n",
      "        0.4692, 0.9113, 0.2025, 0.7728, 0.2409, 0.2789, 0.2331, 0.3550, 0.2409,\n",
      "        0.3178, 0.2475, 0.5260, 0.1974, 0.4524, 0.3035, 0.4572, 0.2545, 0.2407,\n",
      "        0.2280, 0.2180, 0.2885, 0.5768, 0.8155, 0.4130, 0.3694, 0.6659, 0.2362,\n",
      "        0.6913, 0.9650, 0.2370, 0.2500, 0.2409, 0.2228, 0.3197, 0.3787, 0.5711,\n",
      "        0.3663, 0.2948, 0.2464, 0.2332, 0.3095, 0.2922, 0.7976, 0.2221, 0.2567,\n",
      "        0.2794, 0.2650, 0.1976, 0.2221, 0.2518, 0.3197, 0.2475, 0.2368, 0.2239,\n",
      "        0.2794, 0.2464], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([-1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
      "        -1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
      "        -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
      "         1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,\n",
      "        -1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
      "         1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
      "         1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,\n",
      "        -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
      "        -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
      "         1., -1.])\n",
      "predictions:  tensor([ 2.0176e-02,  1.3007e-01,  4.9808e-02,  3.9880e-01,  1.7376e-02,\n",
      "         4.7802e-02,  3.8251e-02,  6.8841e-02,  2.4029e-01,  3.7682e-01,\n",
      "         3.0762e-02,  6.2940e-01, -6.0867e-03,  1.3584e-01,  1.0165e-01,\n",
      "         1.7981e-02,  1.3007e-01,  1.8542e-01,  1.5821e-01,  1.0181e-03,\n",
      "         1.0165e-01,  6.5408e-01,  1.5962e-01,  9.1573e-02,  5.5008e-01,\n",
      "        -1.1693e-04, -1.8947e-02,  5.9871e-01,  3.2323e-02, -1.5316e-02,\n",
      "         3.1980e-01,  3.8876e-01,  3.7120e-01,  6.1351e-01,  1.2019e-01,\n",
      "         2.0176e-02, -3.1192e-03,  2.1126e-02,  7.4765e-02,  6.5153e-01,\n",
      "         3.8232e-01,  9.1603e-02,  1.7640e-01,  3.1980e-01,  1.1384e-02,\n",
      "         8.0083e-01,  6.9158e-01,  4.2210e-02,  4.9808e-02,  1.3730e-02,\n",
      "         2.1346e-01,  3.1307e-01,  1.1960e-01,  4.2253e-02,  1.5938e-01,\n",
      "         4.5050e-02, -1.7954e-02,  2.3686e-02, -2.7597e-02,  4.3291e-02,\n",
      "         5.8435e-02,  5.4057e-02, -3.8691e-02,  1.4171e-01,  2.0160e-01,\n",
      "         3.7519e-02,  6.5153e-01,  2.8291e-01,  1.9966e-01, -3.8112e-02,\n",
      "         1.2448e-01, -8.2536e-03,  6.4398e-02,  7.5584e-01,  2.1433e-01,\n",
      "         5.2338e-02,  2.9829e-01,  5.8435e-02,  5.1826e-01,  8.0177e-01,\n",
      "         7.5584e-01, -2.5225e-03,  3.7682e-01,  2.3686e-02,  6.6897e-02,\n",
      "         6.8264e-02, -6.4515e-03,  9.3716e-02,  2.5132e-02,  2.2341e-01,\n",
      "         1.9644e-01,  3.0762e-02,  4.9564e-01, -6.4515e-03, -1.7954e-02,\n",
      "         4.7165e-01,  3.8876e-01,  3.7518e-02,  2.8291e-01,  1.4857e-02,\n",
      "         2.2719e-01,  1.4059e-01, -3.8691e-02,  1.7981e-02,  1.9650e-02,\n",
      "         8.0177e-01,  6.9158e-01,  3.7731e-01,  1.9966e-01,  1.8591e-02,\n",
      "         9.5145e-02,  2.1346e-01,  1.0266e-01,  6.9158e-01,  6.5408e-01,\n",
      "         5.2954e-02,  1.7376e-02,  1.4154e-01,  2.9649e-02,  6.5408e-01,\n",
      "         4.3569e-01,  1.2204e-01,  8.8374e-02,  2.9649e-02,  1.5155e-01,\n",
      "         2.3686e-02,  2.0634e-02,  1.4799e-01], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "labels:  tensor([ 1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
      "         1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
      "         1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
      "        -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1., -1.,\n",
      "         1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
      "        -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1.,\n",
      "         1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
      "        -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
      "         1.,  1.])\n",
      "predictions:  tensor([ 0.5591,  0.0558, -0.2554, -0.1510,  0.1300, -0.2662, -0.2652,  0.4623,\n",
      "        -0.2355, -0.2222, -0.0473, -0.1053, -0.2256, -0.1697,  0.3535, -0.2491,\n",
      "        -0.0094, -0.2692, -0.2691, -0.2801, -0.2326,  0.1150, -0.1619, -0.2386,\n",
      "        -0.2535, -0.0089, -0.2244, -0.2290, -0.0877, -0.2761,  0.5591, -0.2460,\n",
      "         0.0947, -0.1955, -0.2244, -0.0877, -0.2848, -0.2478, -0.2363,  0.3643,\n",
      "         0.1239, -0.2554, -0.2007, -0.2491,  0.0947, -0.2995, -0.1842, -0.2691,\n",
      "        -0.2526, -0.1241, -0.1797,  0.0966, -0.2853,  0.4623,  0.6471,  0.6119,\n",
      "        -0.2229, -0.2222, -0.3170, -0.2752, -0.2716, -0.1243, -0.2797, -0.2987,\n",
      "        -0.2244, -0.2554,  0.1892, -0.1213, -0.2784, -0.2452, -0.2652, -0.2732,\n",
      "         0.6691, -0.2614, -0.1213, -0.1215, -0.3130, -0.1926, -0.0509,  0.4228,\n",
      "         0.0231, -0.0089, -0.2724, -0.2761, -0.3130,  0.4676,  0.0052, -0.2294,\n",
      "        -0.1215, -0.2249, -0.2752, -0.2850, -0.2661, -0.0046, -0.2861, -0.2614,\n",
      "        -0.1993, -0.2913, -0.2818,  0.6119, -0.2113, -0.2652, -0.1993, -0.1668,\n",
      "        -0.1955, -0.1366,  0.1065, -0.2326, -0.1366, -0.1215, -0.1926, -0.2101,\n",
      "        -0.1603,  0.3535, -0.2007, -0.2995,  0.4228, -0.2393, -0.2756,  0.1300,\n",
      "         0.0231,  0.0796, -0.2826, -0.2662, -0.2414,  0.2415, -0.2244,  0.3612],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([ 1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,\n",
      "        -1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,\n",
      "        -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
      "        -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,\n",
      "        -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        -1., -1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n",
      "         1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,\n",
      "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
      "         1., -1.])\n",
      "predictions:  tensor([-0.2927, -0.3599, -0.2831, -0.0308,  0.1677, -0.2234, -0.1221,  0.0358,\n",
      "        -0.2407, -0.3183, -0.1163, -0.3642, -0.1925, -0.3068, -0.2234, -0.2986,\n",
      "        -0.2339, -0.3635, -0.3571, -0.3309, -0.2979, -0.1332, -0.2970, -0.3491,\n",
      "        -0.3356, -0.3010, -0.3631, -0.2214, -0.3554, -0.2137, -0.1332, -0.1265,\n",
      "        -0.3483, -0.3206, -0.3300,  0.3772, -0.2556, -0.2137,  0.4099, -0.2582,\n",
      "         0.0481,  0.6528, -0.2510,  0.4009, -0.0308,  0.4099,  0.0152, -0.3315,\n",
      "        -0.0724, -0.3301,  0.4009, -0.3301, -0.3538, -0.3731, -0.3134, -0.3308,\n",
      "        -0.0984, -0.2927, -0.3531, -0.0192, -0.2848, -0.3434, -0.1129, -0.2958,\n",
      "        -0.3301, -0.3827, -0.2582,  0.0463, -0.2219, -0.1332,  0.0777, -0.2958,\n",
      "        -0.2688, -0.1138,  0.0777, -0.2738, -0.1158, -0.2369, -0.1950,  0.0358,\n",
      "         0.3772,  0.5809, -0.3550, -0.2407, -0.3409, -0.3362, -0.3599,  0.3851,\n",
      "        -0.1548,  0.0390, -0.2560, -0.3308, -0.3023,  0.0777, -0.2846,  0.3114,\n",
      "        -0.3739, -0.1138,  0.1001, -0.2979, -0.0984, -0.3183,  0.3729,  0.0358,\n",
      "        -0.1299, -0.3085, -0.2545, -0.0724, -0.3008, -0.2831, -0.2127, -0.3036,\n",
      "         0.1596, -0.2730, -0.2560, -0.3314, -0.3438, -0.2710,  0.3851, -0.3413,\n",
      "        -0.1925, -0.3033, -0.2927, -0.2137,  0.2748,  0.2933,  0.0390, -0.2137],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([ 1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,\n",
      "         1., -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,\n",
      "         1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,\n",
      "         1., -1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,\n",
      "        -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1., -1.,\n",
      "        -1., -1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
      "         1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
      "        -1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,\n",
      "        -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
      "         1.,  1.])\n",
      "predictions:  tensor([-0.1834, -0.1825, -0.2365, -0.2681, -0.2510, -0.3116, -0.1625, -0.2657,\n",
      "        -0.0935, -0.2729,  0.1292, -0.2864, -0.2102,  0.4159, -0.2643, -0.2653,\n",
      "        -0.3160, -0.1984, -0.2401, -0.0641,  0.1453, -0.2653, -0.1977,  0.0254,\n",
      "        -0.0641, -0.1511, -0.1032, -0.2790, -0.1799, -0.2966, -0.2288, -0.2966,\n",
      "        -0.2102, -0.3045,  0.2662, -0.3107,  0.0654, -0.1182, -0.3107, -0.0190,\n",
      "        -0.2830, -0.2989, -0.2221, -0.2940,  0.3447, -0.2620, -0.1511, -0.0404,\n",
      "        -0.2008, -0.0356, -0.1935, -0.3261, -0.2221, -0.2271, -0.2221,  0.1286,\n",
      "        -0.3298, -0.2342, -0.2263, -0.2022, -0.2277, -0.2401, -0.2966,  0.4171,\n",
      "         0.1177, -0.2870, -0.1995, -0.2531, -0.1511, -0.2025, -0.1707, -0.1953,\n",
      "        -0.2390, -0.3066, -0.2931, -0.0091, -0.2781, -0.3261, -0.3116, -0.0641,\n",
      "        -0.2927, -0.0401, -0.2940,  0.0837,  0.0341, -0.2729, -0.1511, -0.0141,\n",
      "        -0.2794,  0.0274, -0.2529, -0.2277, -0.1995, -0.2794, -0.0641,  0.6201,\n",
      "        -0.2491, -0.2385, -0.2940, -0.2510, -0.1789, -0.0605,  0.6364, -0.1741,\n",
      "         0.3400, -0.3081, -0.2651, -0.0404, -0.2720, -0.3261, -0.0366,  0.1177,\n",
      "        -0.2885, -0.2480, -0.0935,  0.3447,  0.3542, -0.1935,  0.4628, -0.2363,\n",
      "         0.3400, -0.1266, -0.3261, -0.2454,  0.5532, -0.2857, -0.1562, -0.1236],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([ 1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1., -1.,\n",
      "         1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
      "         1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,\n",
      "        -1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,\n",
      "         1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,\n",
      "        -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.,\n",
      "         1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
      "        -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
      "         1.,  1.])\n",
      "predictions:  tensor([-0.0568, -0.0759, -0.0842, -0.1525, -0.0577, -0.1326,  0.0357,  0.0436,\n",
      "        -0.1264,  0.1965, -0.2013, -0.0944,  0.2079,  0.2517,  0.0348, -0.0225,\n",
      "        -0.0681, -0.1747, -0.0617,  0.0144, -0.0662, -0.0628, -0.0970,  0.0334,\n",
      "         0.1957,  0.3888,  0.1512,  0.0656,  0.5119,  0.3499, -0.1793,  0.0189,\n",
      "        -0.1260,  0.1509, -0.1264,  0.0334,  0.2021, -0.1298, -0.1351, -0.0285,\n",
      "         0.4824, -0.1537, -0.1486, -0.0202, -0.1379,  0.6914,  0.0955, -0.1379,\n",
      "        -0.0681,  0.7011, -0.1148, -0.0617,  0.0158, -0.1334, -0.1055,  0.0321,\n",
      "        -0.1793, -0.0882, -0.0814, -0.1392, -0.1535, -0.0226, -0.1272, -0.0354,\n",
      "        -0.0584, -0.0566, -0.0218, -0.0970,  0.0619, -0.1692, -0.1747,  0.0909,\n",
      "        -0.1388, -0.1065, -0.0955,  0.0441, -0.0225,  0.0288,  0.0357,  0.5806,\n",
      "         0.5637, -0.1136, -0.1313,  0.2312, -0.1100,  0.1512,  0.5119, -0.1103,\n",
      "        -0.1535,  0.2865, -0.1226,  0.3888, -0.0060, -0.0764,  0.0686, -0.1636,\n",
      "         0.5119, -0.0804, -0.0681, -0.0722,  0.0189, -0.0764,  0.0686,  0.2517,\n",
      "        -0.0412,  0.5269, -0.0877, -0.1326,  0.4158, -0.0787,  0.5269,  0.2618,\n",
      "        -0.1148,  0.0805, -0.1174,  0.1077, -0.0983,  0.0357, -0.1003,  0.2079,\n",
      "        -0.0584,  0.0087, -0.0568,  0.3037, -0.1298, -0.1099,  0.3164,  0.0577],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([-1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,\n",
      "        -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
      "        -1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1., -1.,\n",
      "        -1.,  1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,\n",
      "         1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,\n",
      "         1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
      "         1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        -1., -1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
      "         1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.])\n",
      "predictions:  tensor([-0.0668,  0.0011,  0.1199,  0.5987,  0.0245,  0.1698,  0.3992,  0.0494,\n",
      "        -0.0286,  0.1698,  0.0473,  0.3992,  0.0150,  0.0617,  0.0264,  0.0947,\n",
      "         0.1092,  0.2114,  0.0416,  0.0175,  0.2887, -0.0334,  0.3128, -0.0557,\n",
      "         0.4059, -0.0786,  0.0191,  0.1520,  0.0364, -0.0760,  0.1689,  0.3762,\n",
      "         0.0327, -0.0641,  0.0167,  0.1482,  0.2354,  0.1023,  0.2354, -0.0786,\n",
      "         0.1199,  0.0039,  0.1531,  0.4059,  0.0478,  0.1092,  0.1091,  0.0501,\n",
      "        -0.0154,  0.2006,  0.0011,  0.1023,  0.1531,  0.0211, -0.0334,  0.0885,\n",
      "         0.5261,  0.7660,  0.1689,  0.1698,  0.1698,  0.0175, -0.0076,  0.5892,\n",
      "        -0.0641,  0.0726,  0.0809,  0.4486,  0.1379,  0.0419,  0.3941,  0.3465,\n",
      "        -0.1271, -0.0691,  0.1531,  0.0501,  0.2354,  0.3358,  0.1199, -0.0760,\n",
      "         0.2495,  0.0142,  0.3941, -0.0143,  0.1689,  0.0245,  0.0498,  0.1014,\n",
      "         0.1698,  0.0473, -0.0641,  0.1698,  0.3128,  0.4134,  0.4486,  0.5462,\n",
      "         0.0333,  0.0175,  0.1198,  0.1198,  0.0811,  0.0131,  0.1661,  0.0142,\n",
      "         0.0085,  0.0861,  0.2887,  0.1091,  0.3211,  0.2722,  0.2624,  0.1026,\n",
      "         0.1255,  0.0085, -0.0760,  0.0416,  0.2125,  0.0384,  0.1411,  0.0763,\n",
      "         0.0663,  0.1338,  0.3897,  0.0663,  0.2624,  0.4486,  0.0096,  0.2908],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([ 1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,\n",
      "        -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
      "         1., -1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,\n",
      "         1.,  1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1.,\n",
      "         1., -1., -1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,\n",
      "         1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1.,  1.,\n",
      "        -1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,\n",
      "         1., -1.])\n",
      "predictions:  tensor([ 0.3243,  0.0433,  0.2806,  0.3606, -0.0666,  0.1518,  0.4444,  0.2538,\n",
      "         0.1166,  0.0351, -0.0025,  0.0576,  0.1899,  0.2657,  0.5697,  0.2538,\n",
      "         0.1993,  0.2356,  0.7582,  0.2356, -0.0666, -0.0343,  0.1112, -0.0620,\n",
      "         0.0421, -0.0108,  0.1570,  0.4444,  0.0769,  0.6691, -0.0343,  0.0351,\n",
      "         0.2076,  0.2134,  0.0232,  0.5697, -0.0390,  0.2940,  0.0982,  0.3606,\n",
      "         0.1924,  0.2055,  0.4475,  0.0122, -0.0390,  0.4397, -0.0814,  0.0715,\n",
      "         0.1196,  0.0800,  0.3751,  0.2356,  0.1309,  0.2076, -0.0509, -0.0287,\n",
      "         0.3252,  0.3751, -0.0649,  0.1193,  0.0232,  0.0725,  0.0154,  0.0411,\n",
      "         0.7927,  0.1341,  0.6293,  0.1149,  0.0951,  0.5222,  0.3143, -0.1091,\n",
      "        -0.0519,  0.0122,  0.4690,  0.0411,  0.1810,  0.1518,  0.0232,  0.1947,\n",
      "        -0.0519,  0.3024, -0.1091,  0.7927,  0.1570,  0.1694,  0.3983,  0.6550,\n",
      "         0.0982,  0.0863,  0.4125,  0.0513,  0.0322,  0.1424,  0.0513,  0.1166,\n",
      "         0.0873,  0.2657,  0.0909,  0.2663,  0.0421,  0.4304, -0.0063,  0.7927,\n",
      "         0.1140,  0.4475,  0.0948,  0.3751,  0.2467,  0.1160,  0.5498,  0.1510,\n",
      "         0.2279,  0.2988,  0.0863,  0.5409,  0.1076,  0.1362,  0.1690,  0.0183,\n",
      "         0.1728,  0.2134,  0.7983, -0.0509,  0.3335,  0.1193,  0.2806,  0.0513],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([ 1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,\n",
      "        -1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,\n",
      "         1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,\n",
      "         1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,\n",
      "        -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
      "        -1., -1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
      "         1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
      "         1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,\n",
      "         1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
      "         1., -1.])\n",
      "predictions:  tensor([ 0.1800,  0.1669,  0.1832,  0.1813,  0.1957,  0.0142,  0.0486,  0.7582,\n",
      "         0.0016,  0.0070,  0.3010,  0.6013,  0.1449,  0.7582,  0.1745,  0.1012,\n",
      "         0.1293,  0.1522,  0.0893,  0.1832,  0.1440,  0.0343,  0.0586, -0.1055,\n",
      "         0.2305,  0.0486, -0.0676,  0.7795,  0.3344,  0.1430,  0.4355,  0.1393,\n",
      "         0.7795, -0.0956,  0.2863,  0.1218,  0.3344, -0.0317, -0.0956, -0.0739,\n",
      "         0.5169,  0.1482,  0.2335,  0.7795, -0.1216,  0.1841, -0.0699,  0.3562,\n",
      "         0.0343,  0.1469,  0.6719,  0.6123, -0.0118,  0.1419,  0.0140,  0.1912,\n",
      "         0.0586,  0.0861,  0.5604,  0.0993,  0.6779, -0.0627, -0.0717,  0.3298,\n",
      "         0.1419,  0.1293,  0.1775,  0.1512,  0.0538,  0.4296,  0.0559,  0.0332,\n",
      "        -0.0358,  0.0432,  0.4355,  0.1293,  0.1136,  0.3039, -0.0069,  0.0198,\n",
      "        -0.1216, -0.0175,  0.7405,  0.0909,  0.3228,  0.7795, -0.1139,  0.0486,\n",
      "        -0.1527,  0.1693,  0.4854,  0.1632,  0.3298,  0.1522,  0.1422,  0.1294,\n",
      "         0.5067,  0.2863,  0.4355,  0.2305,  0.2372,  0.0909,  0.0942,  0.1512,\n",
      "         0.1433,  0.1478,  0.1576,  0.1800,  0.3344,  0.4020,  0.1957,  0.0486,\n",
      "         0.1440,  0.2459,  0.2008,  0.1140, -0.1288,  0.0586,  0.0993, -0.0739,\n",
      "         0.1706,  0.1430,  0.3562,  0.0770,  0.3222,  0.5604,  0.2816, -0.0229],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([ 1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1., -1., -1., -1.,\n",
      "         1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1., -1.,\n",
      "        -1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
      "         1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,\n",
      "        -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1., -1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
      "         1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
      "         1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
      "        -1.,  1.])\n",
      "predictions:  tensor([ 0.3057,  0.1628,  0.2372,  0.1654,  0.2047,  0.5574, -0.0754,  0.0410,\n",
      "         0.1606,  0.0642,  0.2601, -0.1026, -0.0552,  0.0564,  0.2450, -0.1628,\n",
      "        -0.0389,  0.4355, -0.1628,  0.0733,  0.7560, -0.0754,  0.0635, -0.0218,\n",
      "        -0.0721,  0.3952, -0.0229, -0.0089, -0.0044,  0.6213, -0.1000,  0.1818,\n",
      "         0.1567,  0.0380,  0.1567,  0.2523,  0.1487,  0.3106,  0.1017,  0.6616,\n",
      "         0.0733,  0.2462,  0.3756, -0.1628,  0.3249,  0.3688,  0.1175,  0.2450,\n",
      "        -0.0389,  0.6616,  0.1911,  0.1591, -0.0218,  0.0962,  0.3373, -0.1754,\n",
      "         0.1945,  0.2372, -0.1337,  0.3249,  0.1860,  0.0635,  0.2449,  0.2921,\n",
      "        -0.0364,  0.2462,  0.3952, -0.1000, -0.0666, -0.0229, -0.0044,  0.3119,\n",
      "         0.5376,  0.1628,  0.1628,  0.0732,  0.1741,  0.3237,  0.1815, -0.0552,\n",
      "         0.0145,  0.0642,  0.2523,  0.7423,  0.2921,  0.1818,  0.6603,  0.1911,\n",
      "         0.0565, -0.1194,  0.0062,  0.0635,  0.0196,  0.7253,  0.1741, -0.0985,\n",
      "        -0.0389, -0.2052,  0.2265,  0.0340,  0.3274,  0.0733,  0.1286,  0.7253,\n",
      "         0.0080,  0.4119,  0.1350, -0.0985,  0.1741,  0.1017,  0.3119,  0.1019,\n",
      "         0.7253, -0.0866,  0.4355,  0.7423,  0.3952,  0.0635,  0.0410,  0.2152,\n",
      "         0.3756,  0.1190, -0.0866,  0.1452,  0.3688, -0.0507,  0.0448,  0.1350],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([ 1.,  1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,\n",
      "        -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1.,\n",
      "         1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,\n",
      "         1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n",
      "         1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
      "         1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
      "         1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
      "         1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.,  1.,\n",
      "         1.,  1.])\n",
      "predictions:  tensor([ 0.2916,  0.7508, -0.2525,  0.2029, -0.1994, -0.1513,  0.4907,  0.0350,\n",
      "        -0.0955,  0.1001, -0.0123, -0.2176,  0.3242,  0.7092,  0.0029, -0.1448,\n",
      "         0.0924,  0.5491,  0.2955,  0.0181,  0.1966,  0.2262, -0.1480, -0.1994,\n",
      "        -0.0103,  0.4627,  0.3137, -0.2629,  0.3390, -0.1218, -0.2629,  0.1795,\n",
      "         0.7508, -0.0103, -0.1741,  0.6806, -0.2176, -0.0103, -0.1994,  0.2178,\n",
      "         0.1034,  0.4031,  0.4162,  0.5007,  0.1795,  0.3137,  0.2402, -0.2525,\n",
      "        -0.0671, -0.1480,  0.0350,  0.1923,  0.2261, -0.1501, -0.2525,  0.4663,\n",
      "         0.2769,  0.0527,  0.6563, -0.1876,  0.2257,  0.0848,  0.1661, -0.1876,\n",
      "         0.6374,  0.2143, -0.1560,  0.4040,  0.1275, -0.0537,  0.3277,  0.6649,\n",
      "         0.0443, -0.0027, -0.1784,  0.4362,  0.2444,  0.1275,  0.0029, -0.1241,\n",
      "         0.3287,  0.1275,  0.0349,  0.2143,  0.3027,  0.2725, -0.1218, -0.0884,\n",
      "        -0.0610,  0.2262,  0.2211, -0.0884,  0.4362,  0.2402,  0.4162, -0.0911,\n",
      "         0.7508,  0.0924,  0.3638, -0.2303,  0.2185,  0.2916, -0.2414, -0.2189,\n",
      "         0.4040, -0.0027, -0.0830,  0.0924,  0.0640,  0.7092, -0.0112,  0.0919,\n",
      "         0.2322, -0.2034,  0.4176,  0.2467,  0.3556,  0.0919,  0.2029, -0.2525,\n",
      "        -0.0754, -0.1082, -0.0060, -0.2034,  0.0539,  0.4181,  0.5007,  0.1661],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([ 1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,\n",
      "         1., -1., -1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,\n",
      "         1.,  1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,\n",
      "        -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n",
      "         1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,\n",
      "        -1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1.,\n",
      "        -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
      "         1.,  1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
      "         1.,  1., -1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1., -1., -1.,\n",
      "        -1., -1.])\n",
      "predictions:  tensor([ 4.7103e-01, -3.1651e-01, -4.5308e-02,  3.6391e-01, -1.3751e-01,\n",
      "         3.1933e-01,  1.9449e-01, -2.2279e-01,  3.2354e-01, -2.2902e-01,\n",
      "        -8.1357e-02,  2.1434e-01,  6.8790e-01,  3.9396e-01,  1.1019e-01,\n",
      "        -1.3180e-01, -3.1820e-01, -2.0721e-01, -9.8092e-02,  8.0352e-03,\n",
      "         1.8827e-01,  2.4987e-02, -1.4608e-01,  1.0247e-01,  6.8323e-01,\n",
      "         2.6781e-01, -2.5277e-01, -9.8653e-02,  1.3535e-01,  8.8045e-02,\n",
      "        -2.3648e-02,  5.0491e-01, -4.9556e-02, -3.6637e-02,  2.0126e-01,\n",
      "         1.4097e-02,  1.0247e-01, -1.7951e-01, -3.6637e-02,  2.1434e-01,\n",
      "         2.3261e-01, -1.5192e-01, -2.9890e-01,  1.3535e-01,  2.7551e-01,\n",
      "         7.0851e-01, -2.7725e-01,  5.3362e-01, -8.9834e-02,  1.2343e-01,\n",
      "         3.5411e-02,  2.8168e-01,  1.4080e-01, -3.9850e-02,  4.6311e-01,\n",
      "         6.1308e-02,  2.7077e-01,  3.5313e-01, -1.9104e-01,  2.5890e-01,\n",
      "         4.0804e-01, -2.9754e-02,  3.6115e-01,  2.6781e-01,  2.5890e-01,\n",
      "        -3.1118e-01, -3.1651e-01, -2.5277e-01, -1.9104e-01,  3.7604e-01,\n",
      "        -3.6637e-02, -2.5277e-01, -1.5272e-01,  9.0913e-02, -8.9834e-02,\n",
      "         2.9939e-01,  6.4304e-01, -2.0869e-01,  3.2974e-01,  8.0352e-03,\n",
      "        -3.6637e-02, -1.3751e-01, -2.7624e-01,  7.8737e-02, -3.3071e-01,\n",
      "         2.9447e-01,  4.7103e-01,  1.9449e-01,  6.8897e-02, -4.7056e-04,\n",
      "         5.6388e-01,  3.8689e-01,  8.8045e-02,  3.2974e-01,  8.3322e-02,\n",
      "         3.9498e-01,  7.8737e-02,  6.9068e-01,  2.3261e-01,  2.3261e-01,\n",
      "        -3.5621e-02,  5.6388e-01, -1.9192e-02, -3.1651e-01,  6.8790e-01,\n",
      "         7.0851e-01, -8.9834e-02,  2.7077e-01,  2.7729e-01, -2.6256e-01,\n",
      "        -3.0744e-01,  3.9498e-01,  1.5718e-01,  2.7729e-01, -2.0881e-02,\n",
      "        -3.0976e-01,  7.0403e-02,  1.5349e-01,  1.9240e-01, -1.5272e-01,\n",
      "         5.1753e-01, -1.2507e-01,  7.0403e-02,  7.8737e-02,  1.4097e-02,\n",
      "        -1.3180e-01, -3.0744e-01, -2.0869e-01], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "labels:  tensor([-1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,\n",
      "         1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,\n",
      "         1.,  1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,\n",
      "        -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1.,\n",
      "        -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,\n",
      "         1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,\n",
      "        -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
      "         1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,\n",
      "        -1.,  1.])\n",
      "predictions:  tensor([-0.3382, -0.1007,  0.7203, -0.2470, -0.2261,  0.1489, -0.2952,  0.5898,\n",
      "         0.7491,  0.1248, -0.3750,  0.2399,  0.6486, -0.1166,  0.6970, -0.3511,\n",
      "         0.4402, -0.4209, -0.0748, -0.3962, -0.3269,  0.2611, -0.0629, -0.1382,\n",
      "        -0.2470, -0.1665, -0.1614,  0.4190,  0.4584,  0.4289, -0.1756, -0.2952,\n",
      "        -0.0586, -0.4303,  0.4044,  0.4891, -0.3721, -0.3632,  0.3443, -0.0744,\n",
      "        -0.1025,  0.5741, -0.2470, -0.3506, -0.1756,  0.4923,  0.4044,  0.1934,\n",
      "        -0.3955, -0.0631, -0.2591, -0.0586,  0.0547,  0.5796, -0.1665,  0.1489,\n",
      "        -0.2669,  0.2399, -0.3382, -0.4281, -0.2261,  0.4584,  0.5796, -0.4412,\n",
      "        -0.0748, -0.0364, -0.1933, -0.3414,  0.1430,  0.5536,  0.6970, -0.1101,\n",
      "         0.4482, -0.1933,  0.4350, -0.4412,  0.7694,  0.4698,  0.1430, -0.1479,\n",
      "        -0.1382,  0.7203, -0.4243, -0.0297, -0.3154,  0.6008,  0.2485,  0.4120,\n",
      "        -0.3750,  0.0602, -0.3463,  0.1661, -0.1348,  0.4819, -0.0586,  0.5898,\n",
      "         0.1351,  0.5536,  0.3662, -0.2952, -0.0748,  0.6514,  0.4750,  0.4890,\n",
      "        -0.4242,  0.4584,  0.1661,  0.0941,  0.3423, -0.3750,  0.1961, -0.1348,\n",
      "         0.3660,  0.3871,  0.4044,  0.6514, -0.2454, -0.2558, -0.3150,  0.1536,\n",
      "        -0.3947,  0.4921, -0.2669,  0.3087, -0.3224,  0.4190, -0.3239,  0.2399],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([-1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,\n",
      "        -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
      "        -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,\n",
      "         1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
      "        -1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,\n",
      "        -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
      "        -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1., -1.,\n",
      "        -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,\n",
      "         1.,  1.])\n",
      "predictions:  tensor([-0.3368,  0.4308,  0.3536,  0.5041,  0.2105,  0.6051,  0.5349, -0.5552,\n",
      "        -0.3473,  0.1343, -0.2072, -0.1733,  0.4067,  0.2042,  0.3663,  0.3490,\n",
      "         0.3441,  0.3677,  0.1656, -0.3996,  0.0061, -0.4466,  0.1343,  0.0837,\n",
      "        -0.4160, -0.0665, -0.1503,  0.4872, -0.3528,  0.5063,  0.5988, -0.1637,\n",
      "        -0.3198,  0.6409, -0.4942,  0.3296,  0.1656,  0.2617,  0.5873,  0.1123,\n",
      "        -0.5692, -0.3980, -0.4160, -0.1964, -0.5481, -0.3023, -0.4314,  0.6051,\n",
      "         0.4308, -0.1314,  0.7601,  0.6345,  0.3355,  0.0788, -0.3789,  0.6345,\n",
      "        -0.0331,  0.7895, -0.5205,  0.1233,  0.3355, -0.0236, -0.3996, -0.2810,\n",
      "        -0.2146,  0.4107, -0.5449,  0.5431,  0.4308,  0.4287, -0.3638,  0.4750,\n",
      "         0.3441,  0.3355, -0.1303,  0.0307, -0.4902, -0.3030, -0.5524, -0.3980,\n",
      "         0.2170,  0.3355,  0.5911,  0.1343, -0.4314, -0.5481,  0.4765,  0.6345,\n",
      "         0.7263,  0.3490, -0.5484,  0.5873,  0.6853,  0.5931,  0.5175, -0.4370,\n",
      "         0.7791,  0.4693, -0.2427, -0.5277, -0.1924,  0.3626, -0.4595, -0.2391,\n",
      "         0.0562,  0.3221, -0.1964,  0.4788, -0.2427,  0.5311, -0.3009, -0.1033,\n",
      "        -0.3023, -0.3528, -0.3980,  0.5063, -0.4518, -0.0855,  0.5873,  0.5667,\n",
      "         0.4539, -0.4902, -0.1314, -0.1655,  0.5988,  0.0340,  0.3296,  0.6409],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([-1.,  1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1.,\n",
      "        -1., -1.,  1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
      "        -1., -1.,  1., -1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,\n",
      "        -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        -1.,  1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1., -1.,  1., -1.,\n",
      "         1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n",
      "         1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
      "         1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
      "        -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,\n",
      "        -1., -1.])\n",
      "predictions:  tensor([-0.1233, -0.1866, -0.3415, -0.6333, -0.6333,  0.4761, -0.5949, -0.4168,\n",
      "         0.6798, -0.6515, -0.2250, -0.6312,  0.3584, -0.6842, -0.1371, -0.2920,\n",
      "         0.2677,  0.7982,  0.5086, -0.5640, -0.4071, -0.2075, -0.0804, -0.4512,\n",
      "        -0.4666,  0.5997, -0.6730,  0.0296, -0.4512, -0.4289,  0.1031, -0.6680,\n",
      "         0.4820, -0.4029, -0.0760,  0.3871, -0.6255, -0.5223,  0.3871,  0.0399,\n",
      "         0.1577, -0.5341, -0.5112,  0.5089,  0.6017, -0.2421,  0.1955,  0.0788,\n",
      "        -0.5112, -0.2556,  0.3160,  0.2800, -0.3277,  0.4514,  0.2800,  0.4529,\n",
      "        -0.0578,  0.6029,  0.5106,  0.6017, -0.2075, -0.1179,  0.3541, -0.2920,\n",
      "        -0.6636, -0.5640, -0.0804, -0.1497,  0.3541, -0.1018,  0.5945,  0.3626,\n",
      "        -0.5665, -0.2421,  0.4820,  0.3079, -0.5480,  0.1955,  0.0329, -0.1497,\n",
      "        -0.0578,  0.7982, -0.3415,  0.5590,  0.5870, -0.6233,  0.1955,  0.0265,\n",
      "        -0.2556,  0.4514, -0.6740,  0.4761, -0.4029,  0.5315,  0.1577,  0.0296,\n",
      "        -0.4666,  0.3639,  0.7186, -0.2684,  0.7186,  0.6155, -0.6233, -0.3277,\n",
      "         0.4587,  0.6029,  0.6090, -0.2397,  0.5443,  0.6874,  0.6605,  0.6143,\n",
      "        -0.6437,  0.3792,  0.5631, -0.4666, -0.6542,  0.4353,  0.1048, -0.5665,\n",
      "         0.7982, -0.6138, -0.6149, -0.6609,  0.0999, -0.2585, -0.1379, -0.4666],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([-1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,\n",
      "         1.,  1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.,  1.,\n",
      "         1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
      "        -1., -1., -1.,  1., -1.,  1.,  1., -1., -1., -1., -1., -1.,  1., -1.,\n",
      "        -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
      "        -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1.,\n",
      "        -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
      "         1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,\n",
      "        -1., -1.])\n",
      "predictions:  tensor([-0.7390,  0.7670, -0.1117,  0.1685, -0.2880,  0.7399,  0.5763, -0.7021,\n",
      "         0.5648, -0.4333, -0.6034, -0.7952, -0.6959, -0.6245,  0.7280,  0.5582,\n",
      "        -0.7920, -0.5145, -0.2805,  0.6793,  0.6146, -0.7782, -0.7629, -0.7846,\n",
      "        -0.2287, -0.4954, -0.7110,  0.5582,  0.4253,  0.6858,  0.6700, -0.2880,\n",
      "        -0.6102,  0.6817, -0.1726,  0.5468,  0.1860, -0.6245,  0.1822, -0.2649,\n",
      "        -0.7782, -0.7390, -0.1609, -0.7485, -0.3931,  0.2839, -0.4797,  0.7746,\n",
      "         0.2839, -0.2880, -0.3336, -0.0923, -0.2287, -0.7081,  0.2558, -0.1581,\n",
      "        -0.3104,  0.1672,  0.4039,  0.6683, -0.4797,  0.4165, -0.7629,  0.6276,\n",
      "         0.4165,  0.6964,  0.5582,  0.7501,  0.3397,  0.0835, -0.2880,  0.2829,\n",
      "        -0.1581,  0.6817,  0.5763,  0.5178,  0.7670,  0.3525,  0.7501, -0.1747,\n",
      "        -0.7248, -0.6034,  0.6151,  0.0488, -0.7782, -0.7214,  0.2744,  0.3700,\n",
      "         0.5466, -0.6687,  0.7746, -0.6796, -0.7929,  0.6817, -0.4786, -0.5383,\n",
      "        -0.7485, -0.1747, -0.4333, -0.5830, -0.3931, -0.4888, -0.1609,  0.3525,\n",
      "        -0.7878, -0.3104,  0.0286,  0.3397,  0.0424, -0.7786,  0.0835, -0.7110,\n",
      "        -0.3948, -0.5034, -0.1133, -0.7878,  0.5755,  0.4201, -0.2880,  0.3177,\n",
      "        -0.7952, -0.3408,  0.6793, -0.7637, -0.7930,  0.0434, -0.7782, -0.3336],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([-1., -1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,\n",
      "         1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "        -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
      "        -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,\n",
      "        -1., -1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
      "         1., -1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
      "         1., -1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,\n",
      "        -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,\n",
      "         1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,\n",
      "         1.,  1.])\n",
      "predictions:  tensor([-0.8380, -0.1146, -0.1062, -0.1688, -0.5405,  0.3294, -0.1788, -0.8616,\n",
      "        -0.3690,  0.7618, -0.8542,  0.6263,  0.1238, -0.6180,  0.6871, -0.1714,\n",
      "        -0.8564, -0.8564, -0.2476,  0.1792, -0.5626, -0.2858,  0.5102,  0.8030,\n",
      "         0.7279, -0.4774, -0.0742,  0.8213, -0.7962, -0.1832,  0.4258, -0.8559,\n",
      "         0.0314, -0.7385, -0.7966, -0.8301, -0.7958, -0.7962, -0.5243,  0.6846,\n",
      "        -0.8162, -0.8003, -0.5822, -0.4504,  0.0088, -0.7385, -0.5822,  0.7673,\n",
      "         0.1734,  0.4349, -0.8365,  0.5905, -0.2476,  0.6794, -0.1788,  0.0088,\n",
      "        -0.8130, -0.4241, -0.7385,  0.3244, -0.3437,  0.6671,  0.6036, -0.4265,\n",
      "        -0.4241, -0.7396,  0.4517,  0.4931, -0.5405,  0.5747,  0.7816, -0.2858,\n",
      "        -0.3004, -0.1660,  0.6536,  0.0749, -0.0999, -0.3437, -0.7396,  0.7375,\n",
      "        -0.3737,  0.2760,  0.4517,  0.7501,  0.3039, -0.8559,  0.7501,  0.3158,\n",
      "        -0.0737,  0.8030,  0.8547,  0.7124,  0.6095,  0.0749, -0.7884,  0.3244,\n",
      "         0.8547,  0.6732, -0.7962, -0.1714,  0.3244, -0.5524, -0.8607,  0.7618,\n",
      "         0.1940,  0.1580, -0.5386,  0.5900,  0.0161, -0.2476,  0.5727,  0.2756,\n",
      "         0.7816, -0.8238, -0.4677, -0.8559,  0.0337, -0.5178,  0.3244, -0.8238,\n",
      "        -0.7539,  0.3244,  0.2760, -0.2476, -0.5626, -0.6464, -0.4707,  0.6794],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  tensor([ 1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
      "        -1.,  1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,\n",
      "         1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,\n",
      "        -1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,\n",
      "         1., -1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,\n",
      "        -1.,  1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1.,\n",
      "        -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
      "         1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,\n",
      "         1.,  1.])\n",
      "predictions:  tensor([ 0.1246,  0.4834,  0.6611,  0.7142, -0.7739, -0.1557,  0.7126,  0.5494,\n",
      "         0.0579, -0.1669,  0.3064,  0.0452,  0.1866,  0.8031, -0.4117,  0.6298,\n",
      "        -0.8329, -0.1184,  0.1866, -0.7914,  0.3234, -0.7991, -0.4005, -0.7998,\n",
      "         0.6169, -0.7721, -0.5065,  0.7088,  0.7419,  0.1999,  0.6611,  0.0576,\n",
      "         0.6627,  0.5230, -0.8529, -0.8166,  0.3118, -0.8273,  0.4657, -0.5942,\n",
      "         0.1866, -0.7558, -0.8729, -0.7721,  0.4857,  0.2068, -0.5729, -0.4363,\n",
      "        -0.6734, -0.3309,  0.7126, -0.4117, -0.5462, -0.6933, -0.4363,  0.1168,\n",
      "         0.6898,  0.1246,  0.3689,  0.3420,  0.4584, -0.7991, -0.1566, -0.4591,\n",
      "         0.8031, -0.0818, -0.4781, -0.3870,  0.5716, -0.8420,  0.1866, -0.0888,\n",
      "         0.5642, -0.4645, -0.2649, -0.7866,  0.5716,  0.8159, -0.7206, -0.7303,\n",
      "         0.6611,  0.6611,  0.1246,  0.0576, -0.5421,  0.1973, -0.1669, -0.8329,\n",
      "        -0.5553, -0.5065,  0.7766, -0.1184, -0.4645,  0.8587,  0.0775,  0.6389,\n",
      "        -0.5462,  0.7766, -0.6389, -0.1224, -0.1438,  0.3314, -0.0888, -0.1566,\n",
      "         0.8504, -0.2887,  0.2143,  0.3420,  0.8031, -0.7660, -0.5942, -0.1657,\n",
      "        -0.3870,  0.6060, -0.7721, -0.5154, -0.0771,  0.2068,  0.3248, -0.8166,\n",
      "         0.1940,  0.8135,  0.0957, -0.7721, -0.8659,  0.6186,  0.7248,  0.6498],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "labels:  [ 1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1. -1.  1.  1.  1. -1.  1.\n",
      " -1.  1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1. -1.  1.\n",
      " -1.  1.  1.  1.  1. -1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.  1.\n",
      " -1.  1.  1.  1.  1.  1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1. -1. -1. -1.  1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1.\n",
      "  1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1. -1.  1. -1.  1.  1.\n",
      " -1. -1.  1. -1. -1. -1.  1.  1.  1.  1. -1.  1.  1. -1.  1.  1.  1.  1.\n",
      "  1. -1. -1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1.\n",
      "  1. -1. -1.  1.  1.  1.  1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1.  1.\n",
      " -1. -1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1. -1.  1.  1. -1.  1.  1.\n",
      " -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1.  1.  1. -1.\n",
      " -1.  1. -1. -1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1.  1.  1.  1. -1.\n",
      "  1. -1.  1. -1.  1.  1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.\n",
      "  1.  1.  1.  1.]\n",
      "predictions:  tensor([ 0.1620, -0.7018,  0.7414,  0.8328,  0.8553, -0.2596, -0.0997, -0.8123,\n",
      "        -0.6706, -0.6999,  0.6757,  0.2607, -0.3887,  0.3940,  0.1104,  0.3677,\n",
      "        -0.8170,  0.5370, -0.5915,  0.5840, -0.8169, -0.7708,  0.1586, -0.7722,\n",
      "        -0.7827,  0.7155,  0.0207, -0.4533, -0.7981, -0.0611,  0.7431,  0.5651,\n",
      "        -0.7604, -0.0532, -0.7173,  0.7629, -0.1762,  0.4122, -0.1004,  0.7913,\n",
      "         0.5388, -0.7750,  0.6431, -0.7084, -0.3934,  0.8632, -0.5254, -0.7146,\n",
      "        -0.4727,  0.8329, -0.6083,  0.5136, -0.4577,  0.7585, -0.2141,  0.7525,\n",
      "         0.4257,  0.6542,  0.6970,  0.2891, -0.3646,  0.6528, -0.1925, -0.3822,\n",
      "        -0.6063, -0.7560, -0.5703,  0.3376,  0.2517, -0.0042,  0.7180,  0.7307,\n",
      "         0.1503,  0.2288,  0.2652,  0.7856,  0.1181, -0.5508, -0.0068,  0.6590,\n",
      "        -0.6646,  0.4996, -0.5207,  0.5975,  0.6202, -0.6724, -0.7301, -0.0625,\n",
      "         0.4312, -0.7307,  0.8379,  0.8279,  0.6606,  0.1984, -0.0726, -0.7863,\n",
      "         0.6821, -0.0869,  0.7437, -0.2564,  0.3869,  0.8078,  0.6339, -0.1718,\n",
      "        -0.4771, -0.1569,  0.3702,  0.2709, -0.0966, -0.5815, -0.1396, -0.0751,\n",
      "        -0.8148, -0.8084,  0.6393,  0.5592,  0.3890,  0.7191, -0.0840,  0.6910,\n",
      "         0.5738, -0.7732,  0.7759,  0.5214,  0.7126,  0.7061,  0.8057, -0.7292,\n",
      "        -0.7976, -0.4448,  0.2614, -0.1929, -0.6912, -0.7383,  0.0544,  0.8327,\n",
      "        -0.7737, -0.2930,  0.5206,  0.3954,  0.2447,  0.7607, -0.4015, -0.8030,\n",
      "         0.7954, -0.0930, -0.8118,  0.7639,  0.2961,  0.1901, -0.6268, -0.8187,\n",
      "         0.7916, -0.7887, -0.6008,  0.6136, -0.7324, -0.4852,  0.7507,  0.1339,\n",
      "        -0.3287,  0.8268, -0.0111, -0.2713,  0.1329,  0.3092,  0.6609, -0.5559,\n",
      "        -0.8200,  0.7868, -0.2080, -0.5029, -0.0947,  0.3749,  0.1040,  0.2880,\n",
      "         0.2061, -0.7910,  0.7245,  0.8114, -0.2094, -0.3397, -0.7237, -0.5436,\n",
      "        -0.0904, -0.6412, -0.6579, -0.5519, -0.3599, -0.7370,  0.6981,  0.8525,\n",
      "        -0.1776, -0.2579,  0.2779,  0.6449,  0.6473, -0.5182, -0.0809,  0.0977,\n",
      "         0.1258, -0.1047,  0.2747, -0.6793, -0.8101,  0.2479, -0.4791,  0.7046,\n",
      "        -0.3226,  0.6650, -0.4062,  0.2260,  0.7919,  0.8248,  0.5138,  0.1457,\n",
      "        -0.6140, -0.7380,  0.7873, -0.6266, -0.4085,  0.1722,  0.3422, -0.0179,\n",
      "        -0.7391,  0.6905, -0.3319, -0.8019, -0.4356, -0.6546, -0.6156, -0.3375,\n",
      "        -0.7571, -0.7914, -0.2232, -0.2445,  0.5981,  0.6066, -0.0176, -0.2180,\n",
      "         0.5049,  0.3832, -0.0564, -0.8204, -0.3182,  0.3708, -0.3122, -0.0472,\n",
      "        -0.3026, -0.2818, -0.4361, -0.7113,  0.3553,  0.1255,  0.0857,  0.6936],\n",
      "       dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py12/lib/python3.12/site-packages/pennylane/math/utils.py:227: UserWarning: Contains tensors of types {'autograd', 'torch'}; dispatch will prioritize TensorFlow, PyTorch, and  Jax over Autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'tensor' and 'Tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m space  \u001b[38;5;241m=\u001b[39m [Integer(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_qubits\u001b[39m\u001b[38;5;124m'\u001b[39m), Integer(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m), Real(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m), Integer(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m20\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt_steps\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Run Bayesian optimization\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m res_gp \u001b[38;5;241m=\u001b[39m gp_minimize(objective, space, n_calls\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m-\u001b[39mres_gp\u001b[38;5;241m.\u001b[39mfun\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres_gp\u001b[38;5;241m.\u001b[39mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/skopt/optimizer/gp.py:281\u001b[0m, in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m base_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     base_estimator \u001b[38;5;241m=\u001b[39m cook_estimator(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGP\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    276\u001b[0m         space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[1;32m    277\u001b[0m         random_state\u001b[38;5;241m=\u001b[39mrng\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax),\n\u001b[1;32m    278\u001b[0m         noise\u001b[38;5;241m=\u001b[39mnoise,\n\u001b[1;32m    279\u001b[0m     )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m base_minimize(\n\u001b[1;32m    282\u001b[0m     func,\n\u001b[1;32m    283\u001b[0m     space,\n\u001b[1;32m    284\u001b[0m     base_estimator\u001b[38;5;241m=\u001b[39mbase_estimator,\n\u001b[1;32m    285\u001b[0m     acq_func\u001b[38;5;241m=\u001b[39macq_func,\n\u001b[1;32m    286\u001b[0m     xi\u001b[38;5;241m=\u001b[39mxi,\n\u001b[1;32m    287\u001b[0m     kappa\u001b[38;5;241m=\u001b[39mkappa,\n\u001b[1;32m    288\u001b[0m     acq_optimizer\u001b[38;5;241m=\u001b[39macq_optimizer,\n\u001b[1;32m    289\u001b[0m     n_calls\u001b[38;5;241m=\u001b[39mn_calls,\n\u001b[1;32m    290\u001b[0m     n_points\u001b[38;5;241m=\u001b[39mn_points,\n\u001b[1;32m    291\u001b[0m     n_random_starts\u001b[38;5;241m=\u001b[39mn_random_starts,\n\u001b[1;32m    292\u001b[0m     n_initial_points\u001b[38;5;241m=\u001b[39mn_initial_points,\n\u001b[1;32m    293\u001b[0m     initial_point_generator\u001b[38;5;241m=\u001b[39minitial_point_generator,\n\u001b[1;32m    294\u001b[0m     n_restarts_optimizer\u001b[38;5;241m=\u001b[39mn_restarts_optimizer,\n\u001b[1;32m    295\u001b[0m     x0\u001b[38;5;241m=\u001b[39mx0,\n\u001b[1;32m    296\u001b[0m     y0\u001b[38;5;241m=\u001b[39my0,\n\u001b[1;32m    297\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrng,\n\u001b[1;32m    298\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    299\u001b[0m     space_constraint\u001b[38;5;241m=\u001b[39mspace_constraint,\n\u001b[1;32m    300\u001b[0m     callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    301\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    302\u001b[0m     model_queue_size\u001b[38;5;241m=\u001b[39mmodel_queue_size,\n\u001b[1;32m    303\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/skopt/optimizer/base.py:332\u001b[0m, in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_calls):\n\u001b[1;32m    331\u001b[0m     next_x \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mask()\n\u001b[0;32m--> 332\u001b[0m     next_y \u001b[38;5;241m=\u001b[39m func(next_x)\n\u001b[1;32m    333\u001b[0m     result \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mtell(next_x, next_y)\n\u001b[1;32m    334\u001b[0m     result\u001b[38;5;241m.\u001b[39mspecs \u001b[38;5;241m=\u001b[39m specs\n",
      "Cell \u001b[0;32mIn[15], line 56\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     53\u001b[0m     acc_val \u001b[38;5;241m=\u001b[39m accuracy(clusters_val, predictions_val)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (it \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m opt_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m         _cost \u001b[38;5;241m=\u001b[39m cost(weights, bias, features, clusters)\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     58\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mit\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m5d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Cost: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_cost\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.7f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcc train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_train\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.7f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Acc validation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_val\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.7f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m         )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Compute predictions on validation set\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# predictions_val = np.sign(variational_classifier(weights, bias, feats_val.T))\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# acc_val = accuracy(clusters_val, predictions_val)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# print(\"accuracy: \", acc_val)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Ensure that acc_val is a scalar\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 82\u001b[0m, in \u001b[0;36mcost\u001b[0;34m(weights, bias, X, Y)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcost\u001b[39m(weights, bias, X, Y):\n\u001b[1;32m     81\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m variational_classifier(weights, bias, X\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m square_loss(Y, predictions)\n",
      "Cell \u001b[0;32mIn[14], line 73\u001b[0m, in \u001b[0;36msquare_loss\u001b[0;34m(labels, predictions)\u001b[0m\n\u001b[1;32m     70\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Convert to float if necessary\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Compute mean squared error\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m mse \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean((labels \u001b[38;5;241m-\u001b[39m predictions) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mse\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'tensor' and 'Tensor'"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "# pre-processing data\n",
    "load_data()\n",
    "k_means() # applies k_means++ clustering on data\n",
    "split_data()\n",
    "\n",
    "# Define the search space\n",
    "space  = [Integer(2, 6, name='num_qubits'), Integer(2, 6, name='num_layers'), Real(0.01, 0.1, name='learning_rate'), Integer(5, 20, name='opt_steps')]\n",
    "\n",
    "# Run Bayesian optimization\n",
    "res_gp = gp_minimize(objective, space, n_calls=15, random_state=0)\n",
    "\n",
    "print(f\"Best accuracy: {-res_gp.fun}\")\n",
    "print(f\"Best parameters: {res_gp.x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c1eeb-6ebf-42c1-93c1-b36882eda364",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
