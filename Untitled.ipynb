{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c16a1eaf-7b5f-4c8f-b68c-081837f649a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'NoiseModel' has no attribute 'pauli_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 49\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# # # bit filp\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# # p = 0.01\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# # bitflip = noise.pauli_error([('X', p), ('I', 1-p)])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# phase flip\u001b[39;00m\n\u001b[1;32m     48\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m---> 49\u001b[0m phaseflip \u001b[38;5;241m=\u001b[39m noise\u001b[38;5;241m.\u001b[39mpauli_error([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m, p), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mp)])\n\u001b[1;32m     50\u001b[0m phaseflip2 \u001b[38;5;241m=\u001b[39m noise\u001b[38;5;241m.\u001b[39mpauli_error([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m, p), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mp)])\n\u001b[1;32m     51\u001b[0m noisemy \u001b[38;5;241m=\u001b[39m phaseflip\u001b[38;5;241m.\u001b[39mtensor(phaseflip2)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'NoiseModel' has no attribute 'pauli_error'"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from qiskit_aer.noise import NoiseModel, pauli_error\n",
    "\n",
    "bsz = 32\n",
    "epochs = 30\n",
    "lr = 0.001\n",
    "w_decay = 1e-4\n",
    "\n",
    "\n",
    "############################################################################################################################################################################\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./dataset/mnist/', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=bsz)\n",
    "test_dataset = datasets.MNIST(root='./dataset/mnist/', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=bsz)\n",
    "\n",
    "###########################################################################################################################################################################\n",
    "noise_model = NoiseModel(basis_gates=['id', 'rz', 'sx', 'cx', 'x'])\n",
    "\n",
    "# # # bit filp\n",
    "# # p = 0.01\n",
    "# # bitflip = noise.pauli_error([('X', p), ('I', 1-p)])\n",
    "# # bitflip2 = noise.pauli_error([('X', p), ('I', 1-p)])\n",
    "# # noisemy = bitflip.tensor(bitflip2)\n",
    "# # print(noisemy)\n",
    "# # noise_model.add_all_qubit_quantum_error(bitflip, ['id', 'rz', 'sx', 'x'])\n",
    "# # noise_model.add_all_qubit_quantum_error(noisemy, ['cx'])\n",
    "\n",
    "# phase flip\n",
    "p = 0.01\n",
    "phaseflip = noise.pauli_error([('Z', p), ('I', 1-p)])\n",
    "phaseflip2 = noise.pauli_error([('Z', p), ('I', 1-p)])\n",
    "noisemy = phaseflip.tensor(phaseflip2)\n",
    "noise_model.add_all_qubit_quantum_error(phaseflip, ['id', 'rz', 'sx', 'x'])\n",
    "noise_model.add_all_qubit_quantum_error(noisemy, ['cx'])\n",
    "\n",
    "###########################################################################################################################################################################\n",
    "n_qubits = 16\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)      # w/o noise\n",
    "# dev = qml.device('qiskit.aer', wires=n_qubits, noise_model=noise_model)      # w noise\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, w000, w001, w002, w003, w004, w005, w006, w007, w008, w009, w010, w011, w012, w013, w014, w015,\n",
    "          w100, w101, w102, w103, w104, w105, w106, w107, w108, w109, w110, w111, w112, w113, w114, w115,\n",
    "          x000, x001, x002, x003, x004, x005, x006, x007, x008, x009, x010, x011, x012, x013, x014, x015,\n",
    "          x100, x101, x102, x103, x104, x105, x106, x107, x108, x109, x110, x111, x112, x113, x114, x115,):\n",
    "    for rx in range(16):\n",
    "      qml.RX(inputs[rx], wires=rx)\n",
    "\n",
    "    qml.Rot(*w000, wires=0)\n",
    "    qml.Rot(*w001, wires=1)\n",
    "    qml.Rot(*w002, wires=2)\n",
    "    qml.Rot(*w003, wires=3)\n",
    "    qml.Rot(*w004, wires=4)\n",
    "    qml.Rot(*w005, wires=5)\n",
    "    qml.Rot(*w006, wires=6)\n",
    "    qml.Rot(*w007, wires=7)\n",
    "    qml.Rot(*w008, wires=8)\n",
    "    qml.Rot(*w009, wires=9)\n",
    "    qml.Rot(*w010, wires=10)\n",
    "    qml.Rot(*w011, wires=11)\n",
    "    qml.Rot(*w012, wires=12)\n",
    "    qml.Rot(*w013, wires=13)\n",
    "    qml.Rot(*w014, wires=14)\n",
    "    qml.Rot(*w015, wires=15)\n",
    "    \n",
    "    qml.CRX(x000, wires=[0,1])\n",
    "    qml.CRX(x001, wires=[1,2])\n",
    "    qml.CRX(x002, wires=[2,3])\n",
    "    qml.CRX(x003, wires=[3,4])\n",
    "    qml.CRX(x004, wires=[4,5])\n",
    "    qml.CRX(x005, wires=[5,6])\n",
    "    qml.CRX(x006, wires=[6,7])\n",
    "    qml.CRX(x007, wires=[7,8])\n",
    "    qml.CRX(x008, wires=[8,9])\n",
    "    qml.CRX(x009, wires=[9,10])\n",
    "    qml.CRX(x010, wires=[10,11])\n",
    "    qml.CRX(x011, wires=[11,12])\n",
    "    qml.CRX(x012, wires=[12,13])\n",
    "    qml.CRX(x013, wires=[13,14])\n",
    "    qml.CRX(x014, wires=[14,15])\n",
    "    qml.CRX(x015, wires=[15,0])\n",
    "\n",
    "    for rx in range(16):\n",
    "      qml.RX(inputs[rx], wires=rx)\n",
    "    qml.Rot(*w100, wires=0)\n",
    "    qml.Rot(*w101, wires=1)\n",
    "    qml.Rot(*w102, wires=2)\n",
    "    qml.Rot(*w103, wires=3)\n",
    "    qml.Rot(*w104, wires=4)\n",
    "    qml.Rot(*w105, wires=5)\n",
    "    qml.Rot(*w106, wires=6)\n",
    "    qml.Rot(*w107, wires=7)\n",
    "    qml.Rot(*w108, wires=8)\n",
    "    qml.Rot(*w109, wires=9)\n",
    "    qml.Rot(*w110, wires=10)\n",
    "    qml.Rot(*w111, wires=11)\n",
    "    qml.Rot(*w112, wires=12)\n",
    "    qml.Rot(*w113, wires=13)\n",
    "    qml.Rot(*w114, wires=14)\n",
    "    qml.Rot(*w115, wires=15)\n",
    "    \n",
    "    qml.CRX(x100, wires=[0,1])\n",
    "    qml.CRX(x101, wires=[1,2])\n",
    "    qml.CRX(x102, wires=[2,3])\n",
    "    qml.CRX(x103, wires=[3,4])\n",
    "    qml.CRX(x104, wires=[4,5])\n",
    "    qml.CRX(x105, wires=[5,6])\n",
    "    qml.CRX(x106, wires=[6,7])\n",
    "    qml.CRX(x107, wires=[7,8])\n",
    "    qml.CRX(x108, wires=[8,9])\n",
    "    qml.CRX(x109, wires=[9,10])\n",
    "    qml.CRX(x110, wires=[10,11])\n",
    "    qml.CRX(x111, wires=[11,12])\n",
    "    qml.CRX(x112, wires=[12,13])\n",
    "    qml.CRX(x113, wires=[13,14])\n",
    "    qml.CRX(x114, wires=[14,15])\n",
    "    qml.CRX(x115, wires=[15,0])\n",
    "\n",
    "\n",
    "    return (qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2)), qml.expval(qml.PauliZ(3)), qml.expval(qml.PauliZ(4)),\n",
    "    qml.expval(qml.PauliZ(5)), qml.expval(qml.PauliZ(6)), qml.expval(qml.PauliZ(7)), qml.expval(qml.PauliZ(8)), qml.expval(qml.PauliZ(9)), \n",
    "    qml.expval(qml.PauliZ(10)), qml.expval(qml.PauliZ(11)), qml.expval(qml.PauliZ(12)), qml.expval(qml.PauliZ(13)), qml.expval(qml.PauliZ(14)), \n",
    "    qml.expval(qml.PauliZ(15)))\n",
    "\n",
    "weight_shapes = {\"w000\": 3, \"w001\": 3, \"w002\": 3, \"w003\": 3, \"w004\": 3, \"w005\": 3, \"w006\": 3, \"w007\": 3, \n",
    "          \"w008\": 3, \"w009\": 3, \"w010\": 3, \"w011\": 3, \"w012\": 3, \"w013\": 3, \"w014\": 3, \"w015\": 3, \n",
    "          \"x000\": 1, \"x001\": 1, \"x002\": 1, \"x003\": 1, \"x004\": 1, \"x005\": 1, \"x006\": 1, \"x007\": 1, \n",
    "          \"x008\": 1, \"x009\": 1, \"x010\": 1, \"x011\": 1, \"x012\": 1, \"x013\": 1, \"x014\": 1, \"x015\": 1, \n",
    "          \"w100\": 3, \"w101\": 3, \"w102\": 3, \"w103\": 3, \"w104\": 3, \"w105\": 3, \"w106\": 3, \"w107\": 3, \n",
    "          \"w108\": 3, \"w109\": 3, \"w110\": 3, \"w111\": 3, \"w112\": 3, \"w113\": 3, \"w114\": 3, \"w115\": 3,\n",
    "          \"x100\": 1, \"x101\": 1, \"x102\": 1, \"x103\": 1, \"x104\": 1, \"x105\": 1, \"x106\": 1, \"x107\": 1, \n",
    "          \"x108\": 1, \"x109\": 1, \"x110\": 1, \"x111\": 1, \"x112\": 1, \"x113\": 1, \"x114\": 1, \"x115\": 1}\n",
    "\n",
    "#################################################################################################################################################################################\n",
    "\n",
    "class MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,28x28\n",
    "        self.pool = torch.nn.AvgPool2d(7, 7)                      # 4x4\n",
    "        self.qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.fc1 = torch.nn.Linear(16, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = x.shape[0]\n",
    "        x = self.pool(x).view(b, 16)\n",
    "        x = self.qlayer(x)\n",
    "        out = self.fc1(x)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "###########################################################################################################################################################################\n",
    "def train(model, DEVICE, train_loader, optimizer, epoch):\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        inputs, target = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = F.nll_loss(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print('epoch: %d, batch_idx: %d, acc: %5f %%, loss: %.3f' % (epoch, batch_idx + 1, 100 * correct / total, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "##########################################################################################################################################################################\n",
    "def test(model, DEVICE, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('accuracy on test set: %d %% ' % (100 * correct / total))\n",
    "    acc = 100 * correct / total\n",
    "    return acc\n",
    "\n",
    "###########################################################################################################################################################################\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MNIST().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=w_decay)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "245f5ddf-f38e-418a-b106-40ebbff370f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'NoiseModel' has no attribute 'pauli_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m noise_model \u001b[38;5;241m=\u001b[39m NoiseModel(basis_gates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     49\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[0;32m---> 50\u001b[0m phaseflip \u001b[38;5;241m=\u001b[39m noise\u001b[38;5;241m.\u001b[39mpauli_error([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m, p), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mp)])\n\u001b[1;32m     51\u001b[0m phaseflip2 \u001b[38;5;241m=\u001b[39m noise\u001b[38;5;241m.\u001b[39mpauli_error([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m, p), (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mp)])\n\u001b[1;32m     52\u001b[0m noisemy \u001b[38;5;241m=\u001b[39m phaseflip\u001b[38;5;241m.\u001b[39mtensor(phaseflip2)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'NoiseModel' has no attribute 'pauli_error'"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "from qiskit_aer.noise import NoiseModel as noise\n",
    "\n",
    "bsz = 32\n",
    "epochs = 30\n",
    "lr = 0.001\n",
    "w_decay = 1e-4\n",
    "\n",
    "# Load data\n",
    "trainX = np.loadtxt('trainX.txt')\n",
    "trainY = np.loadtxt('trainY.txt').astype(int)\n",
    "testX = np.loadtxt('testX.txt')\n",
    "testY = np.loadtxt('testY.txt').astype(int)\n",
    "\n",
    "# Normalize data\n",
    "trainX = (trainX - trainX.min()) / (trainX.max() - trainX.min())\n",
    "testX = (testX - testX.min()) / (testX.max() - testX.min())\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "trainX = torch.tensor(trainX, dtype=torch.float32)\n",
    "trainY = torch.tensor(trainY, dtype=torch.long)\n",
    "testX = torch.tensor(testX, dtype=torch.float32)\n",
    "testY = torch.tensor(testY, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(trainX, trainY)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=bsz)\n",
    "test_dataset = TensorDataset(testX, testY)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=bsz)\n",
    "\n",
    "# Define noise model\n",
    "noise_model = NoiseModel(basis_gates=['id', 'rz', 'sx', 'cx', 'x'])\n",
    "\n",
    "p = 0.01\n",
    "phaseflip = noise.pauli_error([('Z', p), ('I', 1-p)])\n",
    "phaseflip2 = noise.pauli_error([('Z', p), ('I', 1-p)])\n",
    "noisemy = phaseflip.tensor(phaseflip2)\n",
    "noise_model.add_all_qubit_quantum_error(phaseflip, ['id', 'rz', 'sx', 'x'])\n",
    "noise_model.add_all_qubit_quantum_error(noisemy, ['cx'])\n",
    "\n",
    "# Define quantum device\n",
    "n_qubits = 16\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)      # w/o noise\n",
    "# dev = qml.device('qiskit.aer', wires=n_qubits, noise_model=noise_model)      # w noise\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, w000, w001, w002, w003, w004, w005, w006, w007, w008, w009, w010, w011, w012, w013, w014, w015,\n",
    "          w100, w101, w102, w103, w104, w105, w106, w107, w108, w109, w110, w111, w112, w113, w114, w115,\n",
    "          x000, x001, x002, x003, x004, x005, x006, x007, x008, x009, x010, x011, x012, x013, x014, x015,\n",
    "          x100, x101, x102, x103, x104, x105, x106, x107, x108, x109, x110, x111, x112, x113, x114, x115):\n",
    "    for rx in range(16):\n",
    "        qml.RX(inputs[rx], wires=rx)\n",
    "\n",
    "    qml.Rot(*w000, wires=0)\n",
    "    qml.Rot(*w001, wires=1)\n",
    "    qml.Rot(*w002, wires=2)\n",
    "    qml.Rot(*w003, wires=3)\n",
    "    qml.Rot(*w004, wires=4)\n",
    "    qml.Rot(*w005, wires=5)\n",
    "    qml.Rot(*w006, wires=6)\n",
    "    qml.Rot(*w007, wires=7)\n",
    "    qml.Rot(*w008, wires=8)\n",
    "    qml.Rot(*w009, wires=9)\n",
    "    qml.Rot(*w010, wires=10)\n",
    "    qml.Rot(*w011, wires=11)\n",
    "    qml.Rot(*w012, wires=12)\n",
    "    qml.Rot(*w013, wires=13)\n",
    "    qml.Rot(*w014, wires=14)\n",
    "    qml.Rot(*w015, wires=15)\n",
    "    \n",
    "    qml.CRX(x000, wires=[0,1])\n",
    "    qml.CRX(x001, wires=[1,2])\n",
    "    qml.CRX(x002, wires=[2,3])\n",
    "    qml.CRX(x003, wires=[3,4])\n",
    "    qml.CRX(x004, wires=[4,5])\n",
    "    qml.CRX(x005, wires=[5,6])\n",
    "    qml.CRX(x006, wires=[6,7])\n",
    "    qml.CRX(x007, wires=[7,8])\n",
    "    qml.CRX(x008, wires=[8,9])\n",
    "    qml.CRX(x009, wires=[9,10])\n",
    "    qml.CRX(x010, wires=[10,11])\n",
    "    qml.CRX(x011, wires=[11,12])\n",
    "    qml.CRX(x012, wires=[12,13])\n",
    "    qml.CRX(x013, wires=[13,14])\n",
    "    qml.CRX(x014, wires=[14,15])\n",
    "    qml.CRX(x015, wires=[15,0])\n",
    "\n",
    "    for rx in range(16):\n",
    "        qml.RX(inputs[rx], wires=rx)\n",
    "    \n",
    "    qml.Rot(*w100, wires=0)\n",
    "    qml.Rot(*w101, wires=1)\n",
    "    qml.Rot(*w102, wires=2)\n",
    "    qml.Rot(*w103, wires=3)\n",
    "    qml.Rot(*w104, wires=4)\n",
    "    qml.Rot(*w105, wires=5)\n",
    "    qml.Rot(*w106, wires=6)\n",
    "    qml.Rot(*w107, wires=7)\n",
    "    qml.Rot(*w108, wires=8)\n",
    "    qml.Rot(*w109, wires=9)\n",
    "    qml.Rot(*w110, wires=10)\n",
    "    qml.Rot(*w111, wires=11)\n",
    "    qml.Rot(*w112, wires=12)\n",
    "    qml.Rot(*w113, wires=13)\n",
    "    qml.Rot(*w114, wires=14)\n",
    "    qml.Rot(*w115, wires=15)\n",
    "    \n",
    "    qml.CRX(x100, wires=[0,1])\n",
    "    qml.CRX(x101, wires=[1,2])\n",
    "    qml.CRX(x102, wires=[2,3])\n",
    "    qml.CRX(x103, wires=[3,4])\n",
    "    qml.CRX(x104, wires=[4,5])\n",
    "    qml.CRX(x105, wires=[5,6])\n",
    "    qml.CRX(x106, wires=[6,7])\n",
    "    qml.CRX(x107, wires=[7,8])\n",
    "    qml.CRX(x108, wires=[8,9])\n",
    "    qml.CRX(x109, wires=[9,10])\n",
    "    qml.CRX(x110, wires=[10,11])\n",
    "    qml.CRX(x111, wires=[11,12])\n",
    "    qml.CRX(x112, wires=[12,13])\n",
    "    qml.CRX(x113, wires=[13,14])\n",
    "    qml.CRX(x114, wires=[14,15])\n",
    "    qml.CRX(x115, wires=[15,0])\n",
    "\n",
    "    return (qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2)), qml.expval(qml.PauliZ(3)), qml.expval(qml.PauliZ(4)),\n",
    "            qml.expval(qml.PauliZ(5)), qml.expval(qml.PauliZ(6)), qml.expval(qml.PauliZ(7)), qml.expval(qml.PauliZ(8)), qml.expval(qml.PauliZ(9)), \n",
    "            qml.expval(qml.PauliZ(10)), qml.expval(qml.PauliZ(11)), qml.expval(qml.PauliZ(12)), qml.expval(qml.PauliZ(13)), qml.expval(qml.PauliZ(14)), \n",
    "            qml.expval(qml.PauliZ(15)))\n",
    "\n",
    "weight_shapes = {\"w000\": 3, \"w001\": 3, \"w002\": 3, \"w003\": 3, \"w004\": 3, \"w005\": 3, \"w006\": 3, \"w007\": 3, \n",
    "          \"w008\": 3, \"w009\": 3, \"w010\": 3, \"w011\": 3, \"w012\": 3, \"w013\": 3, \"w014\": 3, \"w015\": 3, \n",
    "          \"x000\": 1, \"x001\": 1, \"x002\": 1, \"x003\": 1, \"x004\": 1, \"x005\": 1, \"x006\": 1, \"x007\": 1, \n",
    "          \"x008\": 1, \"x009\": 1, \"x010\": 1, \"x011\": 1, \"x012\": 1, \"x013\": 1, \"x014\": 1, \"x015\": 1, \n",
    "          \"w100\": 3, \"w101\": 3, \"w102\": 3, \"w103\": 3, \"w104\": 3, \"w105\": 3, \"w106\": 3, \"w107\": 3, \n",
    "          \"w108\": 3, \"w109\": 3, \"w110\": 3, \"w111\": 3, \"w112\": 3, \"w113\": 3, \"w114\": 3, \"w115\": 3,\n",
    "          \"x100\": 1, \"x101\": 1, \"x102\": 1, \"x103\": 1, \"x104\": 1, \"x105\": 1, \"x106\": 1, \"x107\": 1, \n",
    "          \"x108\": 1, \"x109\": 1, \"x110\": 1, \"x111\": 1, \"x112\": 1, \"x113\": 1, \"x114\": 1, \"x115\": 1}\n",
    "\n",
    "#################################################################################################################################################################################\n",
    "\n",
    "class MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,28x28\n",
    "        self.pool = torch.nn.AvgPool2d(7, 7)                      # 4x4\n",
    "        self.qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.fc1 = torch.nn.Linear(16, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = x.shape[0]\n",
    "        x = self.pool(x).view(b, 16)\n",
    "        x = self.qlayer(x)\n",
    "        out = self.fc1(x)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "###########################################################################################################################################################################\n",
    "def train(model, DEVICE, train_loader, optimizer, epoch):\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        inputs, target = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = F.nll_loss(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print('epoch: %d, batch_idx: %d, acc: %5f %%, loss: %.3f' % (epoch, batch_idx + 1, 100 * correct / total, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "##########################################################################################################################################################################\n",
    "def test(model, DEVICE, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('accuracy on test set: %d %% ' % (100 * correct / total))\n",
    "    acc = 100 * correct / total\n",
    "    return acc\n",
    "\n",
    "###########################################################################################################################################################################\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MNIST().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=w_decay)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "956c2f9e-263c-4831-8eef-71dfda6a6f0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got -3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 210\u001b[0m\n\u001b[1;32m    206\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mw_decay)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 210\u001b[0m     train(model, device, train_loader, optimizer, epoch)\n\u001b[1;32m    211\u001b[0m     test(model, device, test_loader)\n",
      "Cell \u001b[0;32mIn[12], line 172\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, DEVICE, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m    169\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m    170\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 172\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m    173\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(outputs, target)\n\u001b[1;32m    174\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 155\u001b[0m, in \u001b[0;36mMNIST.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    154\u001b[0m     b \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 155\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\u001b[38;5;241m.\u001b[39mview(b, \u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m    156\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqlayer(x)\n\u001b[1;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py12/lib/python3.12/site-packages/torch/nn/modules/pooling.py:631\u001b[0m, in \u001b[0;36mAvgPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mavg_pool2d(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    632\u001b[0m                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mceil_mode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount_include_pad, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisor_override)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got -3)"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import AdamOptimizer, GradientDescentOptimizer\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "\n",
    "bsz = 32\n",
    "epochs = 30\n",
    "lr = 0.001\n",
    "w_decay = 1e-4\n",
    "\n",
    "# Load data\n",
    "trainX = np.loadtxt('trainX.txt')\n",
    "trainY = np.loadtxt('trainY.txt').astype(int)\n",
    "testX = np.loadtxt('testX.txt')\n",
    "testY = np.loadtxt('testY.txt').astype(int)\n",
    "\n",
    "# Normalize data\n",
    "trainX = (trainX - trainX.min()) / (trainX.max() - trainX.min())\n",
    "testX = (testX - testX.min()) / (testX.max() - testX.min())\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "trainX = torch.tensor(trainX, dtype=torch.float32)\n",
    "trainY = torch.tensor(trainY, dtype=torch.long)\n",
    "testX = torch.tensor(testX, dtype=torch.float32)\n",
    "testY = torch.tensor(testY, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(trainX, trainY)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=bsz)\n",
    "test_dataset = TensorDataset(testX, testY)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=bsz)\n",
    "\n",
    "# Define quantum device\n",
    "n_qubits = 16\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)  # w/o noise\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, w000, w001, w002, w003, w004, w005, w006, w007, w008, w009, w010, w011, w012, w013, w014, w015,\n",
    "          w100, w101, w102, w103, w104, w105, w106, w107, w108, w109, w110, w111, w112, w113, w114, w115,\n",
    "          x000, x001, x002, x003, x004, x005, x006, x007, x008, x009, x010, x011, x012, x013, x014, x015,\n",
    "          x100, x101, x102, x103, x104, x105, x106, x107, x108, x109, x110, x111, x112, x113, x114, x115):\n",
    "    for rx in range(16):\n",
    "        qml.RX(inputs[rx], wires=rx)\n",
    "\n",
    "    qml.Rot(*w000, wires=0)\n",
    "    qml.Rot(*w001, wires=1)\n",
    "    qml.Rot(*w002, wires=2)\n",
    "    qml.Rot(*w003, wires=3)\n",
    "    qml.Rot(*w004, wires=4)\n",
    "    qml.Rot(*w005, wires=5)\n",
    "    qml.Rot(*w006, wires=6)\n",
    "    qml.Rot(*w007, wires=7)\n",
    "    qml.Rot(*w008, wires=8)\n",
    "    qml.Rot(*w009, wires=9)\n",
    "    qml.Rot(*w010, wires=10)\n",
    "    qml.Rot(*w011, wires=11)\n",
    "    qml.Rot(*w012, wires=12)\n",
    "    qml.Rot(*w013, wires=13)\n",
    "    qml.Rot(*w014, wires=14)\n",
    "    qml.Rot(*w015, wires=15)\n",
    "    \n",
    "    qml.CRX(x000, wires=[0, 1])\n",
    "    qml.CRX(x001, wires=[1, 2])\n",
    "    qml.CRX(x002, wires=[2, 3])\n",
    "    qml.CRX(x003, wires=[3, 4])\n",
    "    qml.CRX(x004, wires=[4, 5])\n",
    "    qml.CRX(x005, wires=[5, 6])\n",
    "    qml.CRX(x006, wires=[6, 7])\n",
    "    qml.CRX(x007, wires=[7, 8])\n",
    "    qml.CRX(x008, wires=[8, 9])\n",
    "    qml.CRX(x009, wires=[9, 10])\n",
    "    qml.CRX(x010, wires=[10, 11])\n",
    "    qml.CRX(x011, wires=[11, 12])\n",
    "    qml.CRX(x012, wires=[12, 13])\n",
    "    qml.CRX(x013, wires=[13, 14])\n",
    "    qml.CRX(x014, wires=[14, 15])\n",
    "    qml.CRX(x015, wires=[15, 0])\n",
    "\n",
    "    for rx in range(16):\n",
    "        qml.RX(inputs[rx], wires=rx)\n",
    "    \n",
    "    qml.Rot(*w100, wires=0)\n",
    "    qml.Rot(*w101, wires=1)\n",
    "    qml.Rot(*w102, wires=2)\n",
    "    qml.Rot(*w103, wires=3)\n",
    "    qml.Rot(*w104, wires=4)\n",
    "    qml.Rot(*w105, wires=5)\n",
    "    qml.Rot(*w106, wires=6)\n",
    "    qml.Rot(*w107, wires=7)\n",
    "    qml.Rot(*w108, wires=8)\n",
    "    qml.Rot(*w109, wires=9)\n",
    "    qml.Rot(*w110, wires=10)\n",
    "    qml.Rot(*w111, wires=11)\n",
    "    qml.Rot(*w112, wires=12)\n",
    "    qml.Rot(*w113, wires=13)\n",
    "    qml.Rot(*w114, wires=14)\n",
    "    qml.Rot(*w115, wires=15)\n",
    "    \n",
    "    qml.CRX(x100, wires=[0, 1])\n",
    "    qml.CRX(x101, wires=[1, 2])\n",
    "    qml.CRX(x102, wires=[2, 3])\n",
    "    qml.CRX(x103, wires=[3, 4])\n",
    "    qml.CRX(x104, wires=[4, 5])\n",
    "    qml.CRX(x105, wires=[5, 6])\n",
    "    qml.CRX(x106, wires=[6, 7])\n",
    "    qml.CRX(x107, wires=[7, 8])\n",
    "    qml.CRX(x108, wires=[8, 9])\n",
    "    qml.CRX(x109, wires=[9, 10])\n",
    "    qml.CRX(x110, wires=[10, 11])\n",
    "    qml.CRX(x111, wires=[11, 12])\n",
    "    qml.CRX(x112, wires=[12, 13])\n",
    "    qml.CRX(x113, wires=[13, 14])\n",
    "    qml.CRX(x114, wires=[14, 15])\n",
    "    qml.CRX(x115, wires=[15, 0])\n",
    "\n",
    "    return (qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(1)), qml.expval(qml.PauliZ(2)), qml.expval(qml.PauliZ(3)), qml.expval(qml.PauliZ(4)),\n",
    "            qml.expval(qml.PauliZ(5)), qml.expval(qml.PauliZ(6)), qml.expval(qml.PauliZ(7)), qml.expval(qml.PauliZ(8)), qml.expval(qml.PauliZ(9)), \n",
    "            qml.expval(qml.PauliZ(10)), qml.expval(qml.PauliZ(11)), qml.expval(qml.PauliZ(12)), qml.expval(qml.PauliZ(13)), qml.expval(qml.PauliZ(14)), \n",
    "            qml.expval(qml.PauliZ(15)))\n",
    "\n",
    "weight_shapes = {\"w000\": 3, \"w001\": 3, \"w002\": 3, \"w003\": 3, \"w004\": 3, \"w005\": 3, \"w006\": 3, \"w007\": 3, \n",
    "          \"w008\": 3, \"w009\": 3, \"w010\": 3, \"w011\": 3, \"w012\": 3, \"w013\": 3, \"w014\": 3, \"w015\": 3, \n",
    "          \"x000\": 1, \"x001\": 1, \"x002\": 1, \"x003\": 1, \"x004\": 1, \"x005\": 1, \"x006\": 1, \"x007\": 1, \n",
    "          \"x008\": 1, \"x009\": 1, \"x010\": 1, \"x011\": 1, \"x012\": 1, \"x013\": 1, \"x014\": 1, \"x015\": 1, \n",
    "          \"w100\": 3, \"w101\": 3, \"w102\": 3, \"w103\": 3, \"w104\": 3, \"w105\": 3, \"w106\": 3, \"w107\": 3, \n",
    "          \"w108\": 3, \"w109\": 3, \"w110\": 3, \"w111\": 3, \"w112\": 3, \"w113\": 3, \"w114\": 3, \"w115\": 3,\n",
    "          \"x100\": 1, \"x101\": 1, \"x102\": 1, \"x103\": 1, \"x104\": 1, \"x105\": 1, \"x106\": 1, \"x107\": 1, \n",
    "          \"x108\": 1, \"x109\": 1, \"x110\": 1, \"x111\": 1, \"x112\": 1, \"x113\": 1, \"x114\": 1, \"x115\": 1}\n",
    "\n",
    "#################################################################################################################################################################################\n",
    "\n",
    "class MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,28x28\n",
    "        self.pool = torch.nn.AvgPool2d(7, 7)                      # 4x4\n",
    "        self.qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.fc1 = torch.nn.Linear(16, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        b = x.shape[0]\n",
    "        x = self.pool(x).view(b, 16)\n",
    "        x = self.qlayer(x)\n",
    "        out = self.fc1(x)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "###########################################################################################################################################################################\n",
    "def train(model, DEVICE, train_loader, optimizer, epoch):\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        inputs, target = data\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = F.nll_loss(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print('epoch: %d, batch_idx: %d, acc: %5f %%, loss: %.3f' % (epoch, batch_idx + 1, 100 * correct / total, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "##########################################################################################################################################################################\n",
    "def test(model, DEVICE, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('accuracy on test set: %d %% ' % (100 * correct / total))\n",
    "    acc = 100 * correct / total\n",
    "    return acc\n",
    "\n",
    "###########################################################################################################################################################################\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MNIST().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=w_decay)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad12d3-1526-4eda-a659-0da7fe0a6dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
